{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "python_files_dir = \"./python_files/\" # python工具包位置\n",
    "sys.path.append(python_files_dir)\n",
    "import fid_score as official_fid\n",
    "\n",
    "model_files_dir = \"./model_files/\" # 模型位置\n",
    "sys.path.append(model_files_dir)\n",
    "from CIFAR10.models import ResNet20 as ResNet\n",
    "from CIFAR10.models import Rob_predictor as my_Rob_predictor\n",
    "\n",
    "import foolbox as fb\n",
    "from foolbox.attacks import LinfPGD\n",
    "\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image  \n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import spatial\n",
    "import time\n",
    "import PIL.Image\n",
    "import copy\n",
    "import eagerpy as ep\n",
    "\n",
    "import torch\n",
    "import torchvision.utils as utils\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset\n",
    "from torch.autograd import Variable\n",
    "import random\n",
    "\n",
    "device = torch.device(\"cuda:0\") \n",
    "cpu = torch.device(\"cpu\")\n",
    "kd_tree_number = 20 # 通过多少个最近邻生成样本\n",
    "\n",
    "\n",
    "from flask import Flask, render_template, request, jsonify\n",
    "import logging\n",
    "import os\n",
    "import time\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"./python_files\")\n",
    "import my_tools\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "import pickle\n",
    "python_files_dir = \"./python_files/\" # python工具包位置\n",
    "sys.path.append(python_files_dir)\n",
    "\n",
    "model_files_dir = \"./model_files/\" # 模型位置\n",
    "sys.path.append(model_files_dir)\n",
    "import model_files as model_all\n",
    "\n",
    "device_id = 0\n",
    "device = torch.device(\"cuda:\" + str(device_id)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义中间变量字典\n",
    "activation = {}\n",
    "# 用来获取模型中间层输出的hook\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output.detach()\n",
    "    return hook\n",
    "class RegreAttack():\n",
    "    def __init__(self, rel_stepsize: float = 0.01 / 0.3, steps: int = 40, bounds = (0, 1)):\n",
    "        self.rel_stepsize = rel_stepsize\n",
    "        self.steps = steps\n",
    "        self.bounds = bounds\n",
    "        self.loss_fn = nn.MSELoss()\n",
    "\n",
    "    def get_random_start(self, x0, epsilon: float):\n",
    "        x0, restore_type = ep.astensor_(x0)\n",
    "        x = x0 + ep.uniform(x0, x0.shape, -epsilon, epsilon)\n",
    "        return restore_type(x)\n",
    "\n",
    "    def normalize(self, gradients):\n",
    "        return gradients.sign()\n",
    "\n",
    "    # 将\n",
    "    def project(self, x, x0, epsilon: float):\n",
    "        x, x_restore_type = ep.astensor_(x)\n",
    "        x0, x0_restore_type = ep.astensor_(x0)\n",
    "        temp = x0 + ep.clip(x - x0, -epsilon, epsilon)\n",
    "        return x_restore_type(temp)\n",
    "    \n",
    "    def run(self, model, inputs, epsilon: float):\n",
    "        x0 = inputs.clone().detach().requires_grad_()\n",
    "        _min, _max = self.bounds\n",
    "        init_label = model(x0)\n",
    "        # print(\"攻击中的init_label: \", init_label)\n",
    "\n",
    "        # 随机添加扰动，生成新的样本\n",
    "        x = self.get_random_start(x0, epsilon)\n",
    "        x = ep.clip(x, _min, _max)\n",
    "        x = x.clone().detach().requires_grad_()\n",
    "\n",
    "        # 梯度下降攻击\n",
    "        for _ in range(self.steps):\n",
    "            model.zero_grad()  # 清空模型参数的梯度信息\n",
    "            # 计算扰动后的损失\n",
    "            output = model(x)\n",
    "            mse_loss = self.loss_fn(init_label, output)\n",
    "            mse_loss.backward(retain_graph=True)\n",
    "            gradients = x.grad.data\n",
    "\n",
    "            gradients = self.normalize(gradients)\n",
    "            x = x + self.rel_stepsize * gradients * epsilon\n",
    "            x = self.project(x, x0, epsilon)\n",
    "            x = ep.clip(x, _min, _max)\n",
    "            x.grad = None  # 清空 x 的梯度信息\n",
    "            x = x.clone().detach_().requires_grad_()\n",
    "        return x\n",
    "\n",
    "# 通过对抗扰动获取图片真实鲁棒性（回归模型）\n",
    "def adversarial_robustness_regre(model, image_path, label, device):\n",
    "    print(\"获取对抗鲁棒性中.....\")\n",
    "    sys.stdout.flush()\n",
    "    time1 = time.time()\n",
    "    transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.5,0.5,0.5], [0.5,0.5,0.5])\n",
    "            ]\n",
    "        )\n",
    "    image = Image.open(image_path)\n",
    "    image = transform(image)\n",
    "    image = image.unsqueeze(0).to(device)  # 增加一个维度维batch维度\n",
    "    copy_model = copy.deepcopy(model)\n",
    "    copy_model.eval()\n",
    "\n",
    "    attack = RegreAttack()\n",
    "    epsilon = 0.001\n",
    "    flag = False\n",
    "    while(flag == False):\n",
    "        if epsilon >= 0.033:\n",
    "            break\n",
    "        adv = attack.run(copy_model, image, epsilon=epsilon)\n",
    "        label2 = model(adv)[0]\n",
    "        print(\"误差: \", abs(label2 - label))\n",
    "        if abs(label2 - label) >= 0.05: # 0~1对应-80~80度，所以0.03125对应的是误差超过5度，0.05对应8度, 0.0625对应10度\n",
    "            flag=True\n",
    "        epsilon = epsilon + 0.001\n",
    "\n",
    "    sys.stdout.flush()\n",
    "    time2 = time.time()\n",
    "    print(\"获取对抗鲁棒性消耗时间：\", time2-time1)\n",
    "    return epsilon-0.001\n",
    "\n",
    "def get_zs_new(coordinates, kdTree_2D, latent_z, k=50):\n",
    "    '''\n",
    "    coordinates: n个要插值的坐标\n",
    "    kdTree_2D: 降维后的2D坐标\n",
    "    latent_z: 生成模型的输入潜向量，和kdTree_2D是一一对应关系\n",
    "    k: 近邻的数量，也就是lagrange插值的节点数量\n",
    "    '''\n",
    "    print(\"最开始的版本，优化了一下代码~~~~~~~~~~~ k:\",k)\n",
    "    # 直接一次查询所有坐标的k个近邻\n",
    "    nearest_distance, nearest_index = kdTree_2D.query(coordinates, k=k) #这里的k为固定值\n",
    "    origin_coordinates = kdTree_2D.data # 获取kdtree中原始的坐标\n",
    "    for iter in range(len(coordinates)):\n",
    "        iter_distance = nearest_distance[iter]\n",
    "        iter_index = nearest_index[iter]\n",
    "        \n",
    "        sum_distanceForIter = np.sum(iter_distance) #这k个近邻的距离总和\n",
    "        for i, index in enumerate(iter_index):\n",
    "            temp_z = torch.tensor(latent_z[index])\n",
    "            temp_distance = iter_distance[i]\n",
    "            w = (sum_distanceForIter-temp_distance)/((k-1)*sum_distanceForIter) #对z进行权重\n",
    "            if i == 0:\n",
    "                z = temp_z*w\n",
    "            else:\n",
    "                z += temp_z*w\n",
    "        z = z.unsqueeze(0) # shape:[1*latent_dim]\n",
    "        if iter == 0:\n",
    "            zs = z\n",
    "        else:\n",
    "            zs = torch.cat((zs, z), dim=0)\n",
    "        # print(zs.shape)\n",
    "    return zs\n",
    "\n",
    "# 回归模型的版本，只插值z，不动y(y为最近的那一个)\n",
    "def get_zs_new_regre(coordinates, kdTree_2D, latent_z, k=2):\n",
    "    '''\n",
    "    coordinates: n个要插值的坐标\n",
    "    kdTree_2D: 降维后的2D坐标\n",
    "    latent_z: 生成模型的输入潜向量，和kdTree_2D是一一对应关系\n",
    "    k: 近邻的数量，也就是lagrange插值的节点数量\n",
    "    '''\n",
    "    print(\"最开始的版本，优化了一下代码, 不动y，y只取最近的~~~~~~~~~~~ k:\",k)\n",
    "    # 直接一次查询所有坐标的k个近邻\n",
    "    nearest_distance, nearest_index = kdTree_2D.query(coordinates, k=k) #这里的k为固定值\n",
    "    print(nearest_index)\n",
    "    origin_coordinates = kdTree_2D.data # 获取kdtree中原始的坐标\n",
    "    for iter in range(len(coordinates)):\n",
    "        iter_distance = nearest_distance[iter]\n",
    "        iter_index = nearest_index[iter]\n",
    "        \n",
    "        sum_distanceForIter = np.sum(iter_distance) #这k个近邻的距离总和\n",
    "        # 取最近的那一个y\n",
    "        label_y_embed = latent_z[iter_index[0]][256:].clone()\n",
    "        for i, index in enumerate(iter_index):\n",
    "            temp_z = torch.tensor(latent_z[index])\n",
    "            temp_distance = iter_distance[i]\n",
    "            w = (sum_distanceForIter-temp_distance)/((k-1)*sum_distanceForIter) #对z进行权重\n",
    "            if i == 0:\n",
    "                z = temp_z[:256]*w\n",
    "            else:\n",
    "                z += temp_z[:256]*w\n",
    "        # print(label_y_embed)\n",
    "        # print(\"label_y_embed.shape: \", label_y_embed.shape)\n",
    "        # print(\"前z.shape: \", z.shape)\n",
    "        z = torch.cat((z, label_y_embed))\n",
    "        # print(\"后z.shape: \", z.shape)\n",
    "        z = z.unsqueeze(0) # shape:[1*latent_dim]\n",
    "        if iter == 0:\n",
    "            zs = z\n",
    "        else:\n",
    "            zs = torch.cat((zs, z), dim=0)\n",
    "        # print(zs.shape)\n",
    "    return zs\n",
    "\n",
    "def get_image_information_other(points, tree_2D, dict_zs, G, DNN_model, Rob_predictor, img_name=\"one\", dataset_type=\"SteeringAngle\"):\n",
    "    # 根据k个最近邻坐标，计算出坐标对应的z\n",
    "    print(\"取z中.....\")\n",
    "    sys.stdout.flush()\n",
    "    time3 = time.time()\n",
    "    z = get_zs_new_regre([points], tree_2D, dict_zs)\n",
    "    print(\"z.shape: \", z.shape)\n",
    "    time4 = time.time()\n",
    "    print(\"取z消耗时间：\", time4-time3)\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    print(\"生成图片中.....\")\n",
    "    sys.stdout.flush()\n",
    "    time5 = time.time()\n",
    "    # with torch.no_grad(): # 取消梯度计算，加快运行速度\n",
    "    z = torch.tensor(z).to(torch.float32).to(device)    # latent code\n",
    "    \n",
    "    if dataset_type == \"CIFAR10\":\n",
    "        img = G(z) \n",
    "        layer = DNN_model(img) #分类模型分类图片\n",
    "        label = torch.argmax(layer, dim=1)\n",
    "    elif dataset_type == \"SteeringAngle\":\n",
    "        img = G(z[:, :256], z[:, 256:]) \n",
    "        # 注册钩子函数到第二层\n",
    "        DNN_model.pool1.register_forward_hook(get_activation('pool1'))\n",
    "        label = DNN_model(img) #分类模型分类图片\n",
    "        layer = activation[\"pool1\"]\n",
    "        layer = layer.view(layer.size(0), -1)\n",
    "\n",
    "    img = img/2 + 0.5 # [0,1] 归一化图片的范围到0~1区间\n",
    "    utils.save_image(img.detach().cpu(), f'./临时垃圾-随时可删/单个坐标生成的图片保存/'+ img_name +'_' + str(points[0]) + ',' + str(point[1]) + '.png')\n",
    "    # robustness = Rob_predictor(layer) #鲁棒性预测网络预测图片\n",
    "    # robustness = robustness.detach().cpu()\n",
    "    # print(\"robustness.shape: \", robustness.shape)\n",
    "    image_path = './临时垃圾-随时可删/单个坐标生成的图片保存/'+ img_name + '_' + str(points[0]) + ',' + str(point[1]) +'.png'\n",
    "    if dataset_type == \"CIFAR10\":\n",
    "        robustness = adversarial_robustness(DNN_model, image_path, label, device) # 对抗性攻击算法获得鲁棒性\n",
    "    elif dataset_type == \"SteeringAngle\":\n",
    "        robustness = adversarial_robustness_regre(DNN_model, image_path, label, device) # 对抗性攻击算法获得鲁棒性\n",
    "    print(\"robustness: \", robustness)\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    time6 = time.time()\n",
    "    print(\"生成图片消耗时间：\", time6-time5)\n",
    "    sys.stdout.flush()\n",
    "    return label.detach().cpu(), robustness, layer.detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rob_predictor(\n",
       "  (fc1): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (fc3): Linear(in_features=256, out_features=10, bias=True)\n",
       "  (fc4): Linear(in_features=10, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_type = \"SteeringAngle\"\n",
    "model_name = \"ResNet34_regre\"\n",
    "checkpoints_path = \"./model_files/SteeringAngle/checkpoints/CcGAN/ckpt_CcGAN_niters_40000_seed_2020_hard.pth\"\n",
    "G = model_all.get_generative_model(\"SteeringAngle\")\n",
    "G = nn.DataParallel(G, device_ids=[device_id])\n",
    "G.load_state_dict(torch.load(checkpoints_path, map_location=device)[\"netG_state_dict\"])\n",
    "G = G.to(device)\n",
    "G.eval()\n",
    "# 提前加载预处理的数据（降维后的2维坐标和对应的高维向量）\n",
    "tree_2D_path=\"./static/data/SteeringAngle/2D_kdTree/2D_kdTree_200000.pt\"\n",
    "data_z_path=\"./static/data/SteeringAngle/latent_z/CcGAN_384z_200000.pt\"\n",
    "angles_path=\"./static/data/SteeringAngle/angle/angles_200000.pt\"\n",
    "\n",
    "tree_2D = torch.load(tree_2D_path)\n",
    "dict_zs = torch.load(data_z_path, map_location=\"cpu\") #因为我之前保存数据到了GPU上，所以要回到cpu上才不会出错\n",
    "global angles\n",
    "angles = torch.load(angles_path)\n",
    "\n",
    "DNN_model = model_all.get_DNN_model(dataset_type, model_name)\n",
    "DNN_model.load_state_dict(torch.load(\"./model_files/\" + dataset_type + \"/checkpoints/regre_model/\" + model_name + \".pt\", map_location=device)[\"net_state_dict\"])\n",
    "DNN_model.eval()\n",
    "DNN_model.to(device)\n",
    "Rob_predictor = model_all.get_rob_predictor(dataset_type, model_name)\n",
    "Rob_predictor.load_state_dict((torch.load(\"./model_files/\"+ dataset_type + \"/checkpoints/rob_predictor/kjl_rob_predictor_\" + model_name + \"_wrongAngel=8.0epsilon=0.001epsilon_step=0.001.pt\", map_location=device)))\n",
    "Rob_predictor.eval()\n",
    "Rob_predictor.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "取z中.....\n",
      "最开始的版本，优化了一下代码, 不动y，y只取最近的~~~~~~~~~~~ k: 2\n",
      "[[  3644 116979]]\n",
      "z.shape:  torch.Size([1, 384])\n",
      "取z消耗时间： 0.0012350082397460938\n",
      "生成图片中.....\n",
      "获取对抗鲁棒性中.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kuangjielong/.conda/envs/python3_7/lib/python3.7/site-packages/ipykernel_launcher.py:146: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/kuangjielong/.conda/envs/python3_7/lib/python3.7/site-packages/ipykernel_launcher.py:181: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "误差:  tensor([[0.3221]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "获取对抗鲁棒性消耗时间： 1.0263473987579346\n",
      "robustness:  0.001\n",
      "生成图片消耗时间： 1.0638799667358398\n"
     ]
    }
   ],
   "source": [
    "point = [-66.215625, -5.775]\n",
    "point = [-55.190625,-10.434375]\n",
    "point = [-67.594,-8.531]\n",
    "point = [-55.05937500000001,-12.271875000000001]\n",
    "# point = [-39.046875, -14.175000000000004]\n",
    "img_name = \"4\"\n",
    "label, robustness, layer = get_image_information_other(point, tree_2D, dict_zs, G, DNN_model, Rob_predictor, img_name=img_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-64.2508]])\n",
      "0.005\n"
     ]
    }
   ],
   "source": [
    "print((label-0.5)*160)\n",
    "print(robustness)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('python3_7')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b3772b2eda997016c1540bbd3537497480586e8c2c36534a823810c48e399899"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
