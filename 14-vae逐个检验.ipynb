{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "dataset_type = \"CIFAR10\"\n",
    "sample_2D = False\n",
    "sample_208D = False\n",
    "save_origin_pic = False\n",
    "\n",
    "device = torch.device(\"cuda:1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### vae模型以及自定义datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import sys\n",
    "python_files_dir = \"./python_files/\" # python工具包位置\n",
    "sys.path.append(python_files_dir)\n",
    "import my_tools\n",
    "import fid_score as official_fid\n",
    "\n",
    "model_files_dir = \"./model_files/\" # 模型位置\n",
    "sys.path.append(model_files_dir)\n",
    "import model_files as all_model\n",
    "\n",
    "from CIFAR10.models import ResNet20 as classify_model\n",
    "from CIFAR10.models import Rob_predictor as my_Rob_predictor\n",
    "from CIFAR10.models import BigGAN\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "import torchvision.utils as utils\n",
    "\n",
    "import datetime\n",
    "# 定义VAE模型\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        # 编码器\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(208, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.fc_mu = nn.Linear(256, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(256, latent_dim)\n",
    "\n",
    "        # 解码器\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 208),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def encode(self, x):\n",
    "        x = self.encoder(x)\n",
    "        mu = self.fc_mu(x)\n",
    "        logvar = self.fc_logvar(x)\n",
    "        return mu, logvar\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        z = mu + eps * std\n",
    "        return z\n",
    "    \n",
    "    def get_2D(self, x):\n",
    "        mu, logvar = self.encode(x.view(-1, 208))\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return z\n",
    "\n",
    "    def decode(self, z):\n",
    "        x = self.decoder(z)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x.view(-1, 208))\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        x_recon = self.decode(z)\n",
    "        return x_recon, mu, logvar\n",
    "\n",
    "# 自定义datasets\n",
    "class Mydata_sets(Dataset):\n",
    "    def __init__(self, path, device, transform=None):\n",
    "        super(Mydata_sets, self).__init__()\n",
    "        self.latent_z = torch.load(path, map_location=device)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        z = self.latent_z[index].detach()\n",
    "        return z\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.latent_z)\n",
    "\n",
    "# 插值函数\n",
    "def get_zs_prevent_stick(coordinates, kdTree_2D, latent_z, k=50):\n",
    "    '''\n",
    "    nearest_distance: n*k维\n",
    "    nearest_index: n*k维\n",
    "    dict_zs: 键是文件的id号, 值是对应的z（后面直接改成数组了，问题不大）\n",
    "    '''\n",
    "    print(\"进入了防止粘在一块~~~~~~~~~~~~~~~~~~\")\n",
    "    # 直接一次查询所有坐标的k个近邻\n",
    "    nearest_distance, nearest_index = kdTree_2D.query(coordinates, k=k)\n",
    "    origin_coordinates = kdTree_2D.data # 获取kdtree中原始的坐标\n",
    "    for i, pos in enumerate(coordinates): #对每一个坐标进行插值\n",
    "        # pos坐标对应的近邻下标\n",
    "        pos_nearst_index = nearest_index[i] # 其中有k个index，每个index对应kdTree_2D中的一个2维坐标\n",
    "        pos_nearst_distance = nearest_distance[i]\n",
    "\n",
    "        # 最近邻的坐标点，以及最近的距离\n",
    "        most_nearst_pos = origin_coordinates[pos_nearst_index[0]]\n",
    "        most_nearst_dis = pos_nearst_distance[0]\n",
    "\n",
    "        # 利用三角形,找到第二个插值基点，让两边之和越接近第三边，就越是钝角，就越合理\n",
    "        s1 = most_nearst_dis\n",
    "        best_index = 1 # 默认第二个最近邻最好\n",
    "        min_dif = 100\n",
    "        for j in range(1, k):\n",
    "            cur_pos = origin_coordinates[pos_nearst_index[j]]\n",
    "            s2 = pos_nearst_distance[j]\n",
    "            s3 = np.linalg.norm(most_nearst_pos-cur_pos)\n",
    "            if (s1 + s2) - s3 < min_dif: # 两边之和大于等于第三边，所以不用绝对值\n",
    "                min_dif = (s1 + s2) - s3\n",
    "                best_index = j\n",
    "        \n",
    "        temp_z_0 = latent_z[pos_nearst_index[0]].clone().detach()\n",
    "        temp_z_1 = latent_z[pos_nearst_index[best_index]].clone().detach()\n",
    "        sum_distance = most_nearst_dis + pos_nearst_distance[best_index]\n",
    "        z_new = (sum_distance-most_nearst_dis)/(sum_distance) * temp_z_0 + (sum_distance-pos_nearst_distance[best_index])/(sum_distance) * temp_z_1\n",
    "\n",
    "        z_new = z_new.unsqueeze(0)\n",
    "        if i == 0:\n",
    "            zs = z_new\n",
    "        else:\n",
    "            zs = torch.cat((zs, z_new), dim=0)\n",
    "\n",
    "    return zs\n",
    "\n",
    "\n",
    "# 插值函数，不对类向量进行插值，类取最近的那一个点\n",
    "def get_zs_prevent_stick_not_class(coordinates, kdTree_2D, latent_z, k=20):\n",
    "    '''\n",
    "    nearest_distance: n*k维\n",
    "    nearest_index: n*k维\n",
    "    dict_zs: 键是文件的id号, 值是对应的z（后面直接改成数组了，问题不大）\n",
    "    '''\n",
    "    print(\"进入了防止粘在一块，并且不对控制类别的向量进行插值~~~~~~~~~~~~~~~~~~\")\n",
    "    # 直接一次查询所有坐标的k个近邻\n",
    "    nearest_distance, nearest_index = kdTree_2D.query(coordinates, k=k)\n",
    "    origin_coordinates = kdTree_2D.data # 获取kdtree中原始的坐标\n",
    "    for i, pos in enumerate(coordinates): #对每一个坐标进行插值\n",
    "        # pos坐标对应的近邻下标\n",
    "        pos_nearst_index = nearest_index[i] # 其中有k个index，每个index对应kdTree_2D中的一个2维坐标\n",
    "        pos_nearst_distance = nearest_distance[i]\n",
    "\n",
    "        # 最近邻的坐标点，以及最近的距离\n",
    "        most_nearst_pos = origin_coordinates[pos_nearst_index[0]]\n",
    "        most_nearst_dis = pos_nearst_distance[0]\n",
    "\n",
    "        # 利用三角形,找到第二个插值基点，让两边之和越接近第三边，就越是钝角，就越合理\n",
    "        s1 = most_nearst_dis\n",
    "        best_index = 1 # 默认第二个最近邻最好\n",
    "        min_dif = 100\n",
    "        for j in range(1, k):\n",
    "            cur_pos = origin_coordinates[pos_nearst_index[j]]\n",
    "            s2 = pos_nearst_distance[j]\n",
    "            s3 = np.linalg.norm(most_nearst_pos-cur_pos)\n",
    "            if (s1 + s2) - s3 < min_dif: # 两边之和大于等于第三边，所以不用绝对值\n",
    "                min_dif = (s1 + s2) - s3\n",
    "                best_index = j\n",
    "        \n",
    "        temp_z_0 = latent_z[pos_nearst_index[0]].clone().detach()\n",
    "        temp_z_1 = latent_z[pos_nearst_index[best_index]].clone().detach()\n",
    "        sum_distance = most_nearst_dis + pos_nearst_distance[best_index]\n",
    "        z_new = (sum_distance-most_nearst_dis)/(sum_distance) * temp_z_0 + (sum_distance-pos_nearst_distance[best_index])/(sum_distance) * temp_z_1\n",
    "\n",
    "        z_new[-128:] = temp_z_0[-128:] # 不修改类标签\n",
    "\n",
    "        z_new = z_new.unsqueeze(0)\n",
    "        if i == 0:\n",
    "            zs = z_new\n",
    "        else:\n",
    "            zs = torch.cat((zs, z_new), dim=0)\n",
    "\n",
    "    return zs\n",
    "\n",
    "\n",
    "\n",
    "    # 最开始的版本，优化了一下代码\n",
    "\n",
    "\n",
    "# 最开始的版本，就取近邻的向量进行插值\n",
    "def get_zs_new(coordinates, kdTree_2D, latent_z, k=20):\n",
    "    '''\n",
    "    coordinates: n个要插值的坐标\n",
    "    kdTree_2D: 降维后的2D坐标\n",
    "    latent_z: 生成模型的输入潜向量，和kdTree_2D是一一对应关系\n",
    "    k: 近邻的数量\n",
    "    '''\n",
    "    print(\"最开始的版本，优化了一下代码~~~~~~~~~~~ k:\",k)\n",
    "    # 直接一次查询所有坐标的k个近邻\n",
    "    nearest_distance, nearest_index = kdTree_2D.query(coordinates, k=k) #这里的k为固定值\n",
    "    origin_coordinates = kdTree_2D.data # 获取kdtree中原始的坐标\n",
    "    for iter in range(len(coordinates)):\n",
    "        iter_distance = nearest_distance[iter]\n",
    "        iter_index = nearest_index[iter]\n",
    "        \n",
    "        sum_distanceForIter = np.sum(iter_distance) #这k个近邻的距离总和\n",
    "        for i, index in enumerate(iter_index):\n",
    "            temp_z = torch.tensor(latent_z[index])\n",
    "            temp_distance = iter_distance[i]\n",
    "            w = (sum_distanceForIter-temp_distance)/((k-1)*sum_distanceForIter) #对z进行权重\n",
    "            if i == 0:\n",
    "                z = temp_z*w\n",
    "            else:\n",
    "                z += temp_z*w\n",
    "        z = z.unsqueeze(0) # shape:[1*latent_dim]\n",
    "        if iter == 0:\n",
    "            zs = z\n",
    "        else:\n",
    "            zs = torch.cat((zs, z), dim=0)\n",
    "        # print(zs.shape)\n",
    "    return zs\n",
    "\n",
    "\n",
    "# 最开始的版本，就取近邻的向量进行插值，但是不对类的向量进行插值\n",
    "def get_zs_new_not_class(coordinates, kdTree_2D, latent_z, k=50000):\n",
    "    '''\n",
    "    coordinates: n个要插值的坐标\n",
    "    kdTree_2D: 降维后的2D坐标\n",
    "    latent_z: 生成模型的输入潜向量，和kdTree_2D是一一对应关系\n",
    "    k: 近邻的数量\n",
    "    '''\n",
    "    print(\"最开始的版本，优化了一下代码~~~~~~~~~~~ k:\",k)\n",
    "    # 直接一次查询所有坐标的k个近邻\n",
    "    nearest_distance, nearest_index = kdTree_2D.query(coordinates, k=k) #这里的k为固定值\n",
    "    origin_coordinates = kdTree_2D.data # 获取kdtree中原始的坐标\n",
    "    for iter in range(len(coordinates)):\n",
    "        iter_distance = nearest_distance[iter]\n",
    "        iter_index = nearest_index[iter]\n",
    "        \n",
    "        sum_distanceForIter = np.sum(iter_distance) #这k个近邻的距离总和\n",
    "        for i, index in enumerate(iter_index):\n",
    "            temp_z = torch.tensor(latent_z[index])\n",
    "            temp_distance = iter_distance[i]\n",
    "            w = (sum_distanceForIter-temp_distance)/((k-1)*sum_distanceForIter) #对z进行权重\n",
    "            if i == 0:\n",
    "                z = temp_z*w\n",
    "            else:\n",
    "                z += temp_z*w\n",
    "\n",
    "        z[-128:] = latent_z[iter_index[0]][-128:]   #类向量为最近的那一个点的向量\n",
    "\n",
    "        z = z.unsqueeze(0) # shape:[1*latent_dim]\n",
    "        if iter == 0:\n",
    "            zs = z\n",
    "        else:\n",
    "            zs = torch.cat((zs, z), dim=0)\n",
    "        # print(zs.shape)\n",
    "    return zs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 读取vae的名字以及相关数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "path = \"./临时垃圾-随时可删/20230814vae训练\"\n",
    "vae_list = os.listdir(path)\n",
    "# 加载数据集\n",
    "datasets = Mydata_sets('./static/data/CIFAR10/latent_z/BigGAN_random_50k_png_208z_50000.pt', device = device)\n",
    "dataLoader = DataLoader(datasets, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 循环遍历每一个"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######当前vae######\n",
      " vae_state_dict_epoch = 300 kl = 0.015 cl_w = 1.15 loss = 0.027243731689453127 loss_fn=official_2023-08-16 12:46:20.pt\n",
      "z_2ds.shape:  torch.Size([50000, 2])\n",
      "最开始的版本，优化了一下代码~~~~~~~~~~~ k: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kuangjielong/.conda/envs/python3_7/lib/python3.7/site-packages/ipykernel_launcher.py:246: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "生成模型加载成功！\n",
      "正在生成图片。。。。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kuangjielong/.conda/envs/python3_7/lib/python3.7/site-packages/ipykernel_launcher.py:109: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在计算IS。。。。\n",
      "predictions.shape:  torch.Size([50000, 1000])\n",
      "torch.Size([50000])\n",
      "Inception Score: 4.928379535675049\n",
      "fid_model load success!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:52<00:00,  9.59it/s]\n",
      "100%|██████████| 500/500 [00:52<00:00,  9.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma1.shape:  (2048, 2048)\n",
      "sigma2.shape:  (2048, 2048)\n",
      "fid_value:  90.69708481719641\n",
      "######当前vae######\n",
      " vae_state_dict_epoch = 500 kl = 0.021 cl_w = 1.15 loss = 0.027767932628393173 loss_fn=official 2023-08-16 23:07:33.pt\n",
      "z_2ds.shape:  torch.Size([50000, 2])\n",
      "最开始的版本，优化了一下代码~~~~~~~~~~~ k: 20\n",
      "生成模型加载成功！\n",
      "正在生成图片。。。。\n",
      "正在计算IS。。。。\n",
      "predictions.shape:  torch.Size([50000, 1000])\n",
      "torch.Size([50000])\n",
      "Inception Score: 4.940489768981934\n",
      "fid_model load success!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:52<00:00,  9.48it/s]\n",
      "100%|██████████| 500/500 [00:52<00:00,  9.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma1.shape:  (2048, 2048)\n",
      "sigma2.shape:  (2048, 2048)\n",
      "fid_value:  90.49840318569505\n",
      "######当前vae######\n",
      " vae_state_dict_epoch = 100 kl = 0.015 cl_w = 2.0 loss = 0.06301361839294434 loss_fn=official 2023-08-17 20:05:58.pt\n",
      "z_2ds.shape:  torch.Size([50000, 2])\n",
      "最开始的版本，优化了一下代码~~~~~~~~~~~ k: 20\n",
      "生成模型加载成功！\n",
      "正在生成图片。。。。\n",
      "正在计算IS。。。。\n",
      "predictions.shape:  torch.Size([50000, 1000])\n",
      "torch.Size([50000])\n",
      "Inception Score: 4.970670700073242\n",
      "fid_model load success!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:52<00:00,  9.45it/s]\n",
      "100%|██████████| 500/500 [00:53<00:00,  9.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma1.shape:  (2048, 2048)\n",
      "sigma2.shape:  (2048, 2048)\n",
      "fid_value:  90.4513296622033\n",
      "######当前vae######\n",
      " vae_state_dict_epoch = 500 kl = 0.024 cl_w = 1.14 loss = 0.027784584901332857 loss_fn=official 2023-08-17 15:24:26.pt\n",
      "z_2ds.shape:  torch.Size([50000, 2])\n",
      "最开始的版本，优化了一下代码~~~~~~~~~~~ k: 20\n",
      "生成模型加载成功！\n",
      "正在生成图片。。。。\n",
      "正在计算IS。。。。\n",
      "predictions.shape:  torch.Size([50000, 1000])\n",
      "torch.Size([50000])\n",
      "Inception Score: 4.912449836730957\n",
      "fid_model load success!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:53<00:00,  9.29it/s]\n",
      "100%|██████████| 500/500 [00:53<00:00,  9.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma1.shape:  (2048, 2048)\n",
      "sigma2.shape:  (2048, 2048)\n",
      "fid_value:  90.30929244123382\n",
      "######当前vae######\n",
      " vae_state_dict_epoch = 100 kl = 0.015 cl_w = 1.2 loss = 0.028671982766389846 loss_fn=official 2023-08-17 19:07:10.pt\n",
      "z_2ds.shape:  torch.Size([50000, 2])\n",
      "最开始的版本，优化了一下代码~~~~~~~~~~~ k: 20\n",
      "生成模型加载成功！\n",
      "正在生成图片。。。。\n",
      "正在计算IS。。。。\n",
      "predictions.shape:  torch.Size([50000, 1000])\n",
      "torch.Size([50000])\n",
      "Inception Score: 4.90948486328125\n",
      "fid_model load success!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:54<00:00,  9.09it/s]\n",
      "100%|██████████| 500/500 [00:55<00:00,  9.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma1.shape:  (2048, 2048)\n",
      "sigma2.shape:  (2048, 2048)\n",
      "fid_value:  91.40483310435786\n",
      "######当前vae######\n",
      " vae_state_dict_epoch = 100 kl = 0.01 cl_w = 3.0 loss = 0.13633339115142823 loss_fn=official 2023-08-17 20:33:18.pt\n",
      "z_2ds.shape:  torch.Size([50000, 2])\n",
      "最开始的版本，优化了一下代码~~~~~~~~~~~ k: 20\n",
      "生成模型加载成功！\n",
      "正在生成图片。。。。\n",
      "正在计算IS。。。。\n",
      "predictions.shape:  torch.Size([50000, 1000])\n",
      "torch.Size([50000])\n",
      "Inception Score: 4.940021514892578\n",
      "fid_model load success!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:55<00:00,  9.03it/s]\n",
      "100%|██████████| 500/500 [00:55<00:00,  9.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma1.shape:  (2048, 2048)\n",
      "sigma2.shape:  (2048, 2048)\n",
      "fid_value:  91.95861915994976\n",
      "######当前vae######\n",
      " vae_state_dict_epoch = 300 kl = 0.015 cl_w = 1.0 loss = 0.02340015478491783 loss_fn=official_2023-08-16 12:12:47.pt\n",
      "z_2ds.shape:  torch.Size([50000, 2])\n",
      "最开始的版本，优化了一下代码~~~~~~~~~~~ k: 20\n",
      "生成模型加载成功！\n",
      "正在生成图片。。。。\n",
      "正在计算IS。。。。\n",
      "predictions.shape:  torch.Size([50000, 1000])\n",
      "torch.Size([50000])\n",
      "Inception Score: 4.961255073547363\n",
      "fid_model load success!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:55<00:00,  8.98it/s]\n",
      "100%|██████████| 500/500 [00:55<00:00,  8.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma1.shape:  (2048, 2048)\n",
      "sigma2.shape:  (2048, 2048)\n",
      "fid_value:  91.04033191826511\n",
      "######当前vae######\n",
      " vae_state_dict_epoch = 500 kl = 0.024 cl_w = 1.15 loss = 0.02784435513138771 loss_fn=official 2023-08-17 12:01:31.pt\n",
      "z_2ds.shape:  torch.Size([50000, 2])\n",
      "最开始的版本，优化了一下代码~~~~~~~~~~~ k: 20\n",
      "生成模型加载成功！\n",
      "正在生成图片。。。。\n",
      "正在计算IS。。。。\n",
      "predictions.shape:  torch.Size([50000, 1000])\n",
      "torch.Size([50000])\n",
      "Inception Score: 4.943512439727783\n",
      "fid_model load success!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:55<00:00,  9.00it/s]\n",
      "100%|██████████| 500/500 [00:55<00:00,  8.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma1.shape:  (2048, 2048)\n",
      "sigma2.shape:  (2048, 2048)\n",
      "fid_value:  90.51153791746071\n",
      "######当前vae######\n",
      " vae_state_dict_epoch = 500 kl = 0.02 cl_w = 1.15 loss = 0.027547928228378295 loss_fn=official 2023-08-17 18:18:54.pt\n",
      "z_2ds.shape:  torch.Size([50000, 2])\n",
      "最开始的版本，优化了一下代码~~~~~~~~~~~ k: 20\n",
      "生成模型加载成功！\n",
      "正在生成图片。。。。\n",
      "正在计算IS。。。。\n",
      "predictions.shape:  torch.Size([50000, 1000])\n",
      "torch.Size([50000])\n",
      "Inception Score: 4.932520866394043\n",
      "fid_model load success!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:55<00:00,  8.97it/s]\n",
      "100%|██████████| 500/500 [00:55<00:00,  8.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma1.shape:  (2048, 2048)\n",
      "sigma2.shape:  (2048, 2048)\n",
      "fid_value:  90.70113144353434\n",
      "######当前vae######\n",
      " vae_state_dict_epoch = 500 kl = 0.024 cl_w = 1.13 loss = 0.027448162732124328 loss_fn=official 2023-08-17 16:18:46.pt\n",
      "z_2ds.shape:  torch.Size([50000, 2])\n",
      "最开始的版本，优化了一下代码~~~~~~~~~~~ k: 20\n",
      "生成模型加载成功！\n",
      "正在生成图片。。。。\n",
      "正在计算IS。。。。\n",
      "predictions.shape:  torch.Size([50000, 1000])\n",
      "torch.Size([50000])\n",
      "Inception Score: 4.951947212219238\n",
      "fid_model load success!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:55<00:00,  8.97it/s]\n",
      "100%|██████████| 500/500 [00:55<00:00,  8.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma1.shape:  (2048, 2048)\n",
      "sigma2.shape:  (2048, 2048)\n",
      "fid_value:  90.80593005281628\n",
      "######当前vae######\n",
      " vae_state_dict_epoch = 200 kl = 0.015 cl_w = 1.0 loss = 0.023405970087051392 loss_fn=official_2023-08-16 11:40:45.pt\n",
      "z_2ds.shape:  torch.Size([50000, 2])\n",
      "最开始的版本，优化了一下代码~~~~~~~~~~~ k: 20\n",
      "生成模型加载成功！\n",
      "正在生成图片。。。。\n",
      "正在计算IS。。。。\n",
      "predictions.shape:  torch.Size([50000, 1000])\n",
      "torch.Size([50000])\n",
      "Inception Score: 4.908775806427002\n",
      "fid_model load success!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:55<00:00,  8.95it/s]\n",
      "100%|██████████| 500/500 [00:55<00:00,  8.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma1.shape:  (2048, 2048)\n",
      "sigma2.shape:  (2048, 2048)\n",
      "fid_value:  90.84516392214596\n",
      "######当前vae######\n",
      " vae_state_dict_epoch = 300 kl = 0.016 cl_w = 1.15 loss = 0.02730068137526512 loss_fn=official_2023-08-16 15:45:33.pt\n",
      "z_2ds.shape:  torch.Size([50000, 2])\n",
      "最开始的版本，优化了一下代码~~~~~~~~~~~ k: 20\n",
      "生成模型加载成功！\n",
      "正在生成图片。。。。\n",
      "正在计算IS。。。。\n",
      "predictions.shape:  torch.Size([50000, 1000])\n",
      "torch.Size([50000])\n",
      "Inception Score: 4.950687885284424\n",
      "fid_model load success!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:55<00:00,  8.94it/s]\n",
      "100%|██████████| 500/500 [00:56<00:00,  8.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma1.shape:  (2048, 2048)\n",
      "sigma2.shape:  (2048, 2048)\n",
      "fid_value:  90.19607777471316\n",
      "######当前vae######\n",
      " vae_state_dict_epoch = 100 kl = 0.015 cl_w = 1.5 loss = 0.03898269174575806 loss_fn=official 2023-08-17 19:24:05.pt\n",
      "z_2ds.shape:  torch.Size([50000, 2])\n",
      "最开始的版本，优化了一下代码~~~~~~~~~~~ k: 20\n",
      "生成模型加载成功！\n",
      "正在生成图片。。。。\n",
      "正在计算IS。。。。\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image \n",
    "from scipy import spatial\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.utils as utils\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import torch\n",
    "\n",
    "\n",
    "# 用来处理zs的类，方便使用batchsize\n",
    "class My_z_datasets(Dataset):\n",
    "    \n",
    "    def __init__(self, zs):\n",
    "        super(My_z_datasets, self).__init__()\n",
    "        self.zs = zs\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        z = self.zs[index]\n",
    "        return z\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.zs)\n",
    "\n",
    "class My_pic_datasets(Dataset):\n",
    "    \n",
    "    def __init__(self, path, transform=None):\n",
    "        super(My_pic_datasets, self).__init__()\n",
    "        self.root_dir = path\n",
    "        self.img_names = os.listdir(self.root_dir)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_name = self.img_names[index]\n",
    "        img = Image.open(os.path.join(self.root_dir, img_name))\n",
    "        id_name = torch.tensor(int(img_name[4:-4])) #pic_xx.jpg\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img, id_name\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_names)\n",
    "\n",
    "for vae_name in vae_list:\n",
    "    plt.clf()\n",
    "    if not \"vae_state_dict_epoch = 100 kl = 0.015 cl_w = 1.2 loss = 0.028671982766389846 loss_fn=official 2023-08-17 19:07:10.pt\" in vae_name:\n",
    "        continue\n",
    "    print(\"######当前vae######\\n\", vae_name)\n",
    "    vae_path = os.path.join(path, vae_name)\n",
    "    # 初始化VAE模型\n",
    "    vae = VAE(2)\n",
    "    vae.load_state_dict(torch.load(vae_path, map_location=device))\n",
    "    vae = vae.to(device)\n",
    "    vae.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(dataLoader):\n",
    "            data = data.to(device)\n",
    "            if i == 0:\n",
    "                z_2ds = vae.get_2D(data)\n",
    "            else:\n",
    "                z_2d = vae.get_2D(data)\n",
    "                z_2ds = torch.cat((z_2ds, z_2d))\n",
    "    print(\"z_2ds.shape: \", z_2ds.shape)\n",
    "\n",
    "    # 绘制散点图\n",
    "    # 将张量转换为 NumPy 数组\n",
    "    zs_np = z_2ds.to(torch.device(\"cpu\")).detach().numpy()\n",
    "    # 绘制散点图\n",
    "    plt.scatter(zs_np[:, 0], zs_np[:, 1], s=0.01)\n",
    "    plt.xlabel('Dimension 1')\n",
    "    plt.ylabel('Dimension 2')\n",
    "    plt.title(\"vae dimension reduction scatter plot\")\n",
    "    plt.show()\n",
    "    \n",
    "    # 建立搜索树\n",
    "    kdTree = spatial.KDTree(data=zs_np)\n",
    "\n",
    "    # 计算均值和方差\n",
    "    mean_estimated = np.mean(zs_np, axis=0)\n",
    "    cov_estimated = np.cov(zs_np.T)\n",
    "\n",
    "    # 根据方差重新采样\n",
    "    # 生成符合多元正态分布的新坐标点\n",
    "    new_coords = np.random.multivariate_normal(mean_estimated, cov_estimated, size=50000)\n",
    "\n",
    "    latent_z_path=\"./static/data/CIFAR10/latent_z/BigGAN_random_50k_png_208z_50000.pt\"\n",
    "    latent_z = torch.load(latent_z_path, map_location=\"cpu\") #因为我之前保存数据到了GPU上，所以要回到cpu上才不会出错    \n",
    "\n",
    "    zs = get_zs_new_not_class(new_coords, kdTree, latent_z)\n",
    "\n",
    "    zs_datasets = My_z_datasets(zs)\n",
    "    zs_loader = DataLoader(zs_datasets, batch_size=200, shuffle=False, num_workers=1)\n",
    "\n",
    "    model_files_dir = \"./model_files/\" # 模型位置\n",
    "    sys.path.append(model_files_dir)\n",
    "    import model_files as model_all\n",
    "    checkpoints_path = \"./model_files/CIFAR10/checkpoints/BigGAN/model=G-best-weights-step=392000.pth\"\n",
    "    G = model_all.get_generative_model(\"CIFAR10\").to(device)\n",
    "    G.load_state_dict(torch.load(checkpoints_path, map_location=device)[\"state_dict\"])\n",
    "    G.eval()\n",
    "    print(\"生成模型加载成功！\")\n",
    "\n",
    "    first = 0 # 判断是否第一次进入循环\n",
    "    count = 0\n",
    "    print(\"正在生成图片。。。。\")\n",
    "    with torch.no_grad(): # 取消梯度计算，加快运行速度\n",
    "        for batch_z in zs_loader: \n",
    "            z = torch.tensor(batch_z).to(torch.float32).to(device)    # latent code\n",
    "            imgs = G(z)   \n",
    "            for i, img in enumerate(imgs):\n",
    "                img = ((img + 1)/2).clamp(0.0, 1.0) # 变换到[0,1]范围内\n",
    "                utils.save_image(img.detach().cpu(), f'./临时垃圾-随时可删/2D_50k_png/pic_{count}.png')\n",
    "                count += 1\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "    ])\n",
    "    ## !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!计算IS值\n",
    "    # 使用inception_v3获取\n",
    "    from torchvision.models import inception_v3\n",
    "    from torch.utils.data import DataLoader\n",
    "    import torch.nn.functional as F\n",
    "\n",
    "    # 加载预训练的Inception模型\n",
    "    inception_model = inception_v3(pretrained=True, transform_input=False).eval()\n",
    "    inception_model.to(device)\n",
    "\n",
    "\n",
    "    # 生成的图像数据集\n",
    "    generated_dataset = My_pic_datasets(path=\"./临时垃圾-随时可删/2D_50k_png\",transform=transform)\n",
    "    generated_dataloader = DataLoader(generated_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "    # 计算预测分数\n",
    "    print(\"正在计算IS。。。。\")\n",
    "    predictions = []\n",
    "    for images, ids in generated_dataloader:\n",
    "        images = images.to(device)\n",
    "        with torch.no_grad():\n",
    "            images = F.interpolate(images, size=(299, 299), mode='bilinear', align_corners=False)\n",
    "            preds = inception_model(images)\n",
    "        predictions.append(torch.softmax(preds, dim=1))\n",
    "\n",
    "    predictions = torch.cat(predictions, dim=0)\n",
    "    print(\"predictions.shape: \", predictions.shape)\n",
    "\n",
    "    fake_probs = predictions\n",
    "    # fake_probs.mean(dim=0, keepdim=True).shape\n",
    "    # 计算Inception Score\n",
    "    kl_divergence = (fake_probs * (fake_probs / fake_probs.mean(dim=0, keepdim=True)).log()).sum(dim=1)\n",
    "    print(kl_divergence.shape)\n",
    "    inception_score = torch.exp(kl_divergence.mean()).item()\n",
    "    print(\"Inception Score:\", inception_score)\n",
    "\n",
    "\n",
    "    ## !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!计算fid\n",
    "    # fid计算模型\n",
    "    dims = 2048\n",
    "    batch_size = 1\n",
    "    num_avail_cpus = len(os.sched_getaffinity(0))\n",
    "    num_workers = min(num_avail_cpus, 8)\n",
    "    block_idx = official_fid.InceptionV3.BLOCK_INDEX_BY_DIM[2048]\n",
    "    fid_model = official_fid.InceptionV3([block_idx], normalize_input=False).to(device)\n",
    "    # fid_model = official_fid.InceptionV3([block_idx]).to(device)\n",
    "    print('fid_model load success!')\n",
    "\n",
    "    \n",
    "    pic_path_fid1 = \"./static/data/CIFAR10/pic/origin_50k_png\"\n",
    "    pic_path_fid2 = \"./临时垃圾-随时可删/2D_50k_png\"\n",
    "\n",
    "        \n",
    "    batch_size = 100\n",
    "    m1, s1 = official_fid.compute_statistics_of_path(pic_path_fid1, fid_model, batch_size,\n",
    "                                        dims, device, num_workers)\n",
    "    m2, s2 = official_fid.compute_statistics_of_path(pic_path_fid2, fid_model, batch_size,\n",
    "                                        dims, device, num_workers)\n",
    "    fid_value=official_fid.calculate_frechet_distance(m1,s1,m2,s2) \n",
    "    print(\"fid_value: \", fid_value)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
