{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "# from openTSNE import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "import copy\n",
    "# import pandas as pd\n",
    "# import seaborn as sns\n",
    "import random\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.utils as utils\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "import CDCGAN_size32\n",
    "\n",
    "from classify_model.resnet import ResNet18\n",
    "\n",
    "class Mydata_sets2(Dataset):\n",
    "\n",
    "    def __init__(self, zs,labels):\n",
    "        super(Mydata_sets2, self).__init__()\n",
    "        self.zs = zs\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        z = self.zs[index]\n",
    "        labels = self.labels[index]\n",
    "        return z, labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.zs)\n",
    "# ResNet20 = model_all.get_DNN_model(dataset_type, model_name)\n",
    "# ResNet20.load_state_dict( torch.load(\"./model_files/CIFAR10/checkpoints/classify_model/ResNet20.pt\", map_location=device)) # 这个pt文件里不仅仅是参数，包括了模型\n",
    "# # ResNet50 = torch.load(\"./model_files/CIFAR10/checkpoints/classify_model/ResNet50.pt\", map_location=device)\n",
    "# ResNet20 = ResNet20.to(device)\n",
    "# ResNet20.eval()\n",
    "# 加载整个 state_dict\n",
    "checkpoint = torch.load('classify_model/gtsrb_ResNet18_E87_97.85.pth', map_location=device)\n",
    "\n",
    "# 提取模型参数\n",
    "state_dict = checkpoint['model']\n",
    "model = ResNet18().to(device)\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()\n",
    "\n",
    "feature_model = copy.deepcopy(model)\n",
    "feature_model.fc = nn.Identity() # 相当于取消fc层, 这样\n",
    "\n",
    "\n",
    "# checkpoints_g = \"./model_files/CIFAR10/checkpoints/BigGAN/model=G-best-weights-step=392000.pth\"  # kjl测试#############\n",
    "# global G\n",
    "# print(\"数据类型为：\", dataset_type)\n",
    "# G = model_all.get_generative_model(\"CIFAR10\").to(device)\n",
    "# G.load_state_dict(torch.load(checkpoints_path, map_location=device)[\"state_dict\"])\n",
    "# G.eval()\n",
    "G = CDCGAN_size32.generator(128).to(device)\n",
    "G.load_state_dict(torch.load('GTSRB_cDCGAN_results/GTSRB_cDCGAN_generator_param_size32_epoch20.pth'))\n",
    "G.eval()\n",
    "save_path = 'random_size32_50k/'\n",
    "\n",
    "\n",
    "data_z_path = 'GTSRB_cDCGAN_results/cGAN_100z_size32_50k.pt'\n",
    "label_path = 'GTSRB_cDCGAN_results/cGAN_label_size32_50k.pt'\n",
    "dict_zs = torch.load(data_z_path, map_location=\"cpu\")  # 因为我之前保存数据到了GPU上，所以要回到cpu上才不会出错\n",
    "data_z_labels = torch.load(label_path,map_location=\"cpu\")\n",
    "\n",
    "zs_datasets = Mydata_sets2(dict_zs,data_z_labels)\n",
    "    # 不需要前向传播，一次可以多处理一些\n",
    "zs_loader = DataLoader(zs_datasets, batch_size=32, shuffle=False, num_workers=0)  # 指定读取配置信息\n",
    "\n",
    "\n",
    "features, labels, max_values, ids, ten_Ds, picture = [], [], [], [], [], [] # features：提取的2048维图片特征，labels：模型预测的标签，ids图片文件编号\n",
    "# 每个类别的onehot\n",
    "onehot = torch.zeros(43, 43)\n",
    "onehot = onehot.scatter_(1, torch.LongTensor(list(range(43))).view(43, 1), 1).view(43,43, 1, 1)\n",
    "\n",
    "\n",
    "with torch.no_grad():  # 取消梯度计算，加快运行速度\n",
    "    for batch_z, batch_labels in zs_loader:\n",
    "        # z = torch.tensor(batch_z, dtype=torch.float32, device=device).detach()\n",
    "        label_onehot = onehot[batch_labels]\n",
    "        batch_z = batch_z.to(device)\n",
    "        # z = torch.tensor(batch_z).to(torch.float32).to(device).detach()  # latent code\n",
    "        imgs = G(batch_z,label_onehot.to(device))\n",
    "\n",
    "        feature = feature_model(imgs)  # N, 2048\n",
    "        features.append(feature)\n",
    "        # DNN_model.layer3.register_forward_hook(get_activation('layer3'))\n",
    "        layers = model(imgs)  # 分类模型分类图片\n",
    "        # CAMlayer = activation['layer3']\n",
    "        max_value, label = torch.max(layers, dim=1)\n",
    "        same_labels_mask = torch.eq(label, batch_labels.to(device))\n",
    "        # 将不同标签对应的置信度设为负值\n",
    "        max_value = torch.where(same_labels_mask, max_value, -max_value)\n",
    "        picture.append(imgs)\n",
    "        # label = torch.argmax(ten_D, dim=1)\n",
    "        ten_Ds.append(layers)\n",
    "        labels.append(label)\n",
    "        max_values.append(max_value)\n",
    "\n",
    "picture = torch.cat(picture, dim=0).squeeze().view(50000,-1).cpu().numpy()\n",
    "ten_Ds = torch.cat(ten_Ds, dim=0).squeeze().cpu().numpy()  # (n, 10)\n",
    "features = torch.cat(features, dim=0).squeeze().cpu().numpy()  # (n, 2048)\n",
    "labels = torch.cat(labels, dim=0).squeeze().cpu().numpy()  # n\n",
    "max_values = torch.cat(max_values, dim=0).squeeze().cpu().numpy()  # n\n",
    "# ids = torch.cat(ids, dim=0).cpu().numpy() # n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 43)\n",
      "[ 2.7215562  -1.6361705  -1.7730188   6.5197697  -2.6341603   3.5241795\n",
      "  0.29564893  0.1613927   2.123111   -0.87722903 -1.8821998  -1.7636718\n",
      " -2.662229   -1.671491   -0.26688498 -1.437731   -0.33685526 -1.5680554\n",
      " -2.7254262  -2.5143743  -2.2004719  -2.006973   -2.3314602  -0.9256389\n",
      " -2.4634888  -1.5855974  -2.2062507  -3.619819    0.11257693  0.08280019\n",
      " -0.6412584  -2.927784   -0.3935014  -0.8714204  -3.2288659  -1.4881755\n",
      " -1.9513947  -2.18876    -2.0772343  -2.1968708  -3.4484189  -2.4181497\n",
      " -2.095231  ]\n",
      "(50000, 43)\n",
      "[ 2.7215562  -1.6361705  -1.7730188   6.5197697  -2.6341603   3.5241795\n",
      "  0.29564893  0.1613927   2.123111   -0.87722903 -1.8821998  -1.7636718\n",
      " -2.662229   -1.671491   -0.26688498 -1.437731   -0.33685526 -1.5680554\n",
      " -2.7254262  -2.5143743  -2.2004719  -2.006973   -2.3314602  -0.9256389\n",
      " -2.4634888  -1.5855974  -2.2062507  -3.619819    0.11257693  0.08280019\n",
      " -0.6412584  -2.927784   -0.3935014  -0.8714204  -3.2288659  -1.4881755\n",
      " -1.9513947  -2.18876    -2.0772343  -2.1968708  -3.4484189  -2.4181497\n",
      " -2.095231  ]\n"
     ]
    }
   ],
   "source": [
    "# 保存numpy数组到文件\n",
    "import matplotlib.pyplot as plt\n",
    "from openTSNE import TSNE\n",
    "import pandas as pd\n",
    "# np.save('./temp/pic/AE_conf+_/labels.npy', labels)\n",
    "# np.save('./temp/pic/AE_conf+_/max_values.npy', max_values)\n",
    "# np.save('./temp/pic/AE_conf+_/ten_feature.npy', ten_Ds)\n",
    "# np.save('./temp/pic/AE_conf+_/picture.npy', picture)\n",
    "# np.save('./temp/pic/AE_conf+_/features.npy', features)\n",
    "\n",
    "print(features.shape)\n",
    "print(features[0])\n",
    "print(ten_Ds.shape)\n",
    "print(ten_Ds[0])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "embed = TSNE(n_jobs=4).fit(features)  # N, 2\n",
    "pd_embed = pd.DataFrame(embed)\n",
    "print(pd_embed.shape)\n",
    "\n",
    "# np.save('./temp/pic/AE_conf+_/embed_2dim.npy', pd_embed)\n",
    "x = pd_embed.iloc[:, 0]\n",
    "y = pd_embed.iloc[:, 1]\n",
    "# loaded_labels = np.load('./temp/pic/AE/labels.npy')\n",
    "\n",
    "# 绘制二维散点图\n",
    "plt.figure(figsize=(8, 6))\n",
    "# plt.scatter(x, y, c=loaded_labels, cmap='viridis')\n",
    "plt.scatter(x, y, c=labels, cmap='viridis')\n",
    "plt.colorbar(label='Labels')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.title('Scatter Plot of Embeddings')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0          1\n",
      "0 -14.334624 -14.059534\n",
      "1 -19.629860  56.927075\n",
      "2 -65.175466 -60.814551\n",
      "3 -23.933736 -20.852627\n",
      "4  26.891039  -9.420960\n",
      "Scaled Coordinates:\n",
      "           0         1\n",
      "0  0.434617  0.429415\n",
      "1  0.409387  0.767280\n",
      "2  0.192382  0.206881\n",
      "3  0.388881  0.397083\n",
      "4  0.631039  0.451492\n"
     ]
    }
   ],
   "source": [
    "from scipy import spatial\n",
    "\n",
    "print(pd_embed[:5])\n",
    "\n",
    "# 找到每个维度的最小值和最大值\n",
    "min_x, min_y = np.min(pd_embed, axis=0)\n",
    "max_x, max_y = np.max(pd_embed, axis=0)\n",
    "\n",
    "# 缩放坐标到0到1的范围内\n",
    "scaled_value = (pd_embed - [min_x, min_y]) / [max_x - min_x, max_y - min_y]\n",
    "\n",
    "print(\"Scaled Coordinates:\\n\", scaled_value[:5])\n",
    "\n",
    "tree = spatial.KDTree(data=scaled_value)\n",
    "\n",
    "# torch.save(tree, \"./static/data/CIFAR10/2D_kdTree/2D_kdTree_50000_png_2024-3-25.pt\")\n",
    "torch.save(tree, \"GTSRB_cDCGAN_results/2D_kdTree_50000_png_features.pt\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
