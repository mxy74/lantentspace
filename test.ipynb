{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3137, -0.2343, -0.2598,  ...,  0.3202,  0.1208,  0.3160],\n",
      "        [-0.3530,  0.3746, -0.6394,  ...,  1.2815, -1.0512,  0.4020],\n",
      "        [-0.3342,  0.7872,  1.1393,  ...,  0.9954,  0.3982, -0.1756],\n",
      "        ...,\n",
      "        [ 1.0368, -1.5813, -1.3166,  ..., -0.2105,  0.2834, -0.0563],\n",
      "        [ 0.4424,  0.2943, -0.7222,  ...,  0.5979, -0.2894,  0.5395],\n",
      "        [-0.8879, -1.5638,  0.0421,  ...,  0.0127, -0.8769, -0.4331]])\n",
      "tensor([ 1.1524,  0.4685, -0.4043, -0.2357,  0.7016, -1.8937, -0.8826,  0.7821,\n",
      "         1.8177, -1.4871,  0.1369, -0.9920,  0.8324,  2.4257,  0.4230,  0.8006,\n",
      "        -0.0288,  0.6204, -0.0035,  0.1284])\n",
      "tensor([[ 0.3615, -0.2701, -0.2994,  ...,  0.3690,  0.1392,  0.3641],\n",
      "        [-0.1654,  0.1755, -0.2996,  ...,  0.6004, -0.4925,  0.1883],\n",
      "        [ 0.1351, -0.3182, -0.4606,  ..., -0.4024, -0.1610,  0.0710],\n",
      "        ...,\n",
      "        [ 0.6432, -0.9810, -0.8168,  ..., -0.1306,  0.1758, -0.0349],\n",
      "        [-0.0015, -0.0010,  0.0025,  ..., -0.0021,  0.0010, -0.0019],\n",
      "        [-0.1140, -0.2007,  0.0054,  ...,  0.0016, -0.1126, -0.0556]])\n",
      "torch.Size([20, 208])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 示例数据\n",
    "tensor = torch.randn(20, 208)\n",
    "print(tensor)\n",
    "array = torch.ones(20)\n",
    "print(array)\n",
    "\n",
    "# 使用广播进行逐元素相乘\n",
    "result = tensor * array[:, None]\n",
    "print(result)\n",
    "\n",
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2]\n",
      " [ 3  4]\n",
      " [-1 -2]\n",
      " [-3 -4]\n",
      " [ 5  6]\n",
      " [ 7  8]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 假设你有多个坐标数组\n",
    "coordinates1 = np.array([[1, 2], [3, 4]])\n",
    "coordinates2 = np.array([[-1, -2], [-3, -4]])\n",
    "coordinates3 = np.array([[5, 6], [7, 8]])\n",
    "\n",
    "# 使用np.concatenate拼接多个坐标数组\n",
    "concatenated_coordinates = np.concatenate((coordinates1, coordinates2, coordinates3), axis=0)\n",
    "\n",
    "# 输出拼接后的坐标数组\n",
    "print(concatenated_coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.95421144 -0.33070105]\n",
      " [ 2.76442321  2.8665593 ]\n",
      " [ 1.43510268  6.48145762]\n",
      " [ 1.97998607 -1.20769878]\n",
      " [-2.20094633 -9.26259   ]\n",
      " [-1.90915286 -9.28809286]\n",
      " [-1.21387105  8.57863729]\n",
      " [ 4.79646532  7.80184994]\n",
      " [ 4.91048413 -0.5817656 ]\n",
      " [ 2.86792761  6.08856682]\n",
      " [ 0.91605945 -1.19011172]\n",
      " [ 2.76795229  3.14863458]\n",
      " [ 0.93103147  6.72381333]\n",
      " [ 0.21805831 -3.08385264]\n",
      " [ 0.78999723 -8.67441866]\n",
      " [ 4.53464525 -5.80838098]\n",
      " [ 0.39090905 -0.10051034]\n",
      " [ 3.17428622 -6.36454641]\n",
      " [ 3.10644563  1.37178036]\n",
      " [ 0.47271897  0.49039984]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 指定范围和坐标数量\n",
    "x_min, x_max = -5, 5\n",
    "y_min, y_max = -10, 10\n",
    "num_points = 20\n",
    "\n",
    "# 生成随机二维坐标数组\n",
    "coordinates = np.random.uniform(low=[x_min, y_min], high=[x_max, y_max], size=(num_points, 2))\n",
    "\n",
    "# 输出生成的坐标数组\n",
    "print(coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4299,  0.7589, -2.3195, -1.4332, -1.0441],\n",
      "        [ 0.7392, -0.2756,  1.6840, -1.3824,  0.9535],\n",
      "        [ 0.1019,  1.0550, -1.6938, -0.3221, -1.5224]], requires_grad=True)\n",
      "tensor([3, 4, 3])\n",
      "tensor(2.0278, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "input1 = torch.randn(3, 5, requires_grad=True)\n",
    "print(input1)\n",
    "target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "print(target)\n",
    "output = loss(input1, target)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.6.9 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "weights = np.linspace(1.0, 0.0, 10)\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.6.9 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from flask import Flask, render_template, request, jsonify\n",
    "import logging\n",
    "import os\n",
    "import time\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"./python_files\")\n",
    "import my_tools\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import pickle\n",
    "from scipy import spatial\n",
    "python_files_dir = \"./python_files/\" # python工具包位置\n",
    "sys.path.append(python_files_dir)\n",
    "\n",
    "model_files_dir = \"./model_files/\" # 模型位置\n",
    "sys.path.append(model_files_dir)\n",
    "import model_files as model_all\n",
    "\n",
    "device_id = 2\n",
    "device = torch.device(\"cuda:\" + str(device_id)) \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "python_files_dir = \"./python_files/\" # python工具包位置\n",
    "sys.path.append(python_files_dir)\n",
    "import fid_score as official_fid\n",
    "\n",
    "model_files_dir = \"./model_files/\" # 模型位置\n",
    "sys.path.append(model_files_dir)\n",
    "from CIFAR10.models import ResNet20 as ResNet\n",
    "from CIFAR10.models import Rob_predictor as my_Rob_predictor\n",
    "\n",
    "import foolbox as fb\n",
    "from foolbox.attacks import LinfPGD\n",
    "\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image  \n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import spatial\n",
    "import time\n",
    "import PIL.Image\n",
    "import copy\n",
    "import eagerpy as ep\n",
    "\n",
    "import torch\n",
    "import torchvision.utils as utils\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset\n",
    "from torch.autograd import Variable\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "#kjl测试####################################################start\n",
    "# 定义VAE模型\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        # 编码器\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(208, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.fc_mu = nn.Linear(256, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(256, latent_dim)\n",
    "\n",
    "        # 解码器\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 208),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def encode(self, x):\n",
    "        x = self.encoder(x)\n",
    "        mu = self.fc_mu(x)\n",
    "        logvar = self.fc_logvar(x)\n",
    "        return mu, logvar\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        z = mu + eps * std\n",
    "        return z\n",
    "    \n",
    "    def get_2D(self, x):\n",
    "        mu, logvar = self.encode(x.view(-1, 208))\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return z\n",
    "\n",
    "    def decode(self, z):\n",
    "        x = self.decoder(z)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x.view(-1, 208))\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        x_recon = self.decode(z)\n",
    "        return x_recon, mu, logvar\n",
    "\n",
    "vae_path = os.path.join(\"./临时垃圾-随时可删/20230814vae训练\", \"vae_state_dict_epoch = 100 kl = 0.01 cl_w = 3.0 loss = 0.13633339115142823 loss_fn=official 2023-08-17 20:33:18.pt\")\n",
    "# 初始化VAE模型\n",
    "vae = VAE(2)\n",
    "vae.load_state_dict(torch.load(vae_path, map_location=device))\n",
    "vae = vae.to(device)\n",
    "vae.eval()\n",
    "# 加载数据集\n",
    "# 自定义datasets\n",
    "class Mydata_sets__(Dataset):\n",
    "    def __init__(self, path, device, transform=None):\n",
    "        super(Mydata_sets__, self).__init__()\n",
    "        self.latent_z = torch.load(path, map_location=device)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        z = self.latent_z[index].detach()\n",
    "        return z\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.latent_z)\n",
    "\n",
    "datasets = Mydata_sets__('./static/data/CIFAR10/latent_z/BigGAN_random_50k_png_208z_50000.pt', device = device)\n",
    "dataLoader = DataLoader(datasets, batch_size=32, shuffle=True)\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(dataLoader):\n",
    "        data = data.to(device)\n",
    "        if i == 0:\n",
    "            z_2ds = vae.get_2D(data)\n",
    "        else:\n",
    "            z_2d = vae.get_2D(data)\n",
    "            z_2ds = torch.cat((z_2ds, z_2d))\n",
    "print(\"z_2ds.shape: \", z_2ds.shape)\n",
    "# 将张量转换为 NumPy 数组\n",
    "zs_np = z_2ds.to(torch.device(\"cpu\")).detach().numpy()\n",
    "\n",
    "# 画图检查\n",
    "plt.scatter(zs_np[:, 0], zs_np[:, 1], s=0.05)\n",
    "plt.xlabel('Dimension 1')\n",
    "plt.ylabel('Dimension 2')\n",
    "# 保存图像\n",
    "plt.savefig('test_vae.png') \n",
    "\n",
    "# 建立搜索树\n",
    "kdTree_2D = spatial.KDTree(data=zs_np)\n",
    "data_z_path=\"./static/data/CIFAR10/latent_z/BigGAN_random_50k_png_208z_50000.pt\"\n",
    "latent_z = torch.load(data_z_path, map_location=\"cpu\") #因为我之前保存数据到了GPU上，所以要回到cpu上才不会出错\n",
    "\n",
    "k = 10000\n",
    "coordinates = [[0,0]]\n",
    "nearest_distance, nearest_index = kdTree_2D.query(coordinates, k=k)\n",
    "origin_coordinates = kdTree_2D.data # 获取kdtree中原始的坐标\n",
    "for i, pos in enumerate(coordinates): #对每一个坐标进行插值\n",
    "    # pos坐标对应的近邻下标\n",
    "    pos_nearst_index = nearest_index[i] # 其中有k个index，每个index对应kdTree_2D中的一个2维坐标\n",
    "    pos_nearst_distance = nearest_distance[i]\n",
    "\n",
    "    ##########################test\n",
    "    # print(\"当前坐标：\", pos)\n",
    "    # for j in range(len(pos_nearst_index)):\n",
    "    #     print(\"最近的坐标：\", origin_coordinates[pos_nearst_index[j]])\n",
    "    #     print(\"最近的距离：\", pos_nearst_distance[j])\n",
    "    #     print(\"对应的类向量：\", latent_z[pos_nearst_index[j]][-128:])\n",
    "    # print(\"暂时结束\")\n",
    "    # return\n",
    "    ##########################end\n",
    "\n",
    "    # 最近邻的坐标点，以及最近的距离\n",
    "    most_nearst_pos = origin_coordinates[pos_nearst_index[0]]\n",
    "    most_nearst_dis = pos_nearst_distance[0]\n",
    "\n",
    "    # 利用三角形,找到第二个插值基点，让两边之和越接近第三边，就越是钝角，就越合理\n",
    "    s1 = most_nearst_dis\n",
    "    best_index = 1 # 默认第二个最近邻最好\n",
    "    min_dif = 100\n",
    "\n",
    "    fun_dic = {}\n",
    "    for j in range(1, k):\n",
    "        cur_pos = origin_coordinates[pos_nearst_index[j]]\n",
    "        s2 = pos_nearst_distance[j]\n",
    "        s3 = np.linalg.norm(most_nearst_pos-cur_pos)\n",
    "        if (s1 + s2) - s3 < min_dif: # 两边之和大于等于第三边，所以不用绝对值\n",
    "            min_dif = (s1 + s2) - s3\n",
    "            best_index = j\n",
    "\n",
    "        \n",
    "        # 统计一下最近邻居中最多的类别###################test\n",
    "        class_v = str(latent_z[pos_nearst_index[j]][-128:].detach().numpy())\n",
    "        # print(\"当前类别向量：\",class_v)\n",
    "        if class_v in fun_dic.keys():\n",
    "            fun_dic[class_v] += 1\n",
    "        else:\n",
    "            fun_dic[class_v] = 1\n",
    "        # print(latent_z[pos_nearst_index[j]][-128:])\n",
    "    print(\"当前数量向量数量为：\", len(fun_dic.keys()))\n",
    "    print(\"对应的值：\", list(fun_dic.values()))\n",
    "    if i > 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.6.9 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda:1\") \n",
    "dataset_type = \"SteeringAngle\"\n",
    "model_name = \"null\"\n",
    "save_origin_pic = False # 是否保留原始图片\n",
    "save_generate_pic = False # 是否保留生成图片\n",
    "fid_judge = False # 是否进行fid评估\n",
    "\n",
    "if dataset_type == \"CIFAR10\":\n",
    "    ResNet50 = torch.load(\"./model_files/CIFAR10/checkpoints/classify_model/ResNet50.pt\", map_location=device) # 这个pt文件里不仅仅是参数，包括了模型\n",
    "    ResNet50 = ResNet50.to(device)\n",
    "    ResNet50.eval()\n",
    "    train_dataloader = DataLoader(datasets.CIFAR10('./static/data/CIFAR10/CIFAR10/', train=False, download=True, transform=transform), batch_size=128, shuffle=False)\n",
    "\n",
    "class Mydata_sets(Dataset):\n",
    "    \n",
    "    def __init__(self, path, transform=None):\n",
    "        super(Mydata_sets, self).__init__()\n",
    "        self.root_dir = path\n",
    "        self.img_names = os.listdir(self.root_dir)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_name = self.img_names[index]\n",
    "        img = Image.open(os.path.join(self.root_dir, img_name))\n",
    "        id_name = torch.tensor(int(img_name[4:-4])) #pic_xx.jpg\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img, id_name\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_names)\n",
    "\n",
    "if dataset_type == \"CIFAR10\":\n",
    "    transform = transforms.Compose([\n",
    "        transforms.PILToTensor(),\n",
    "        transforms.ConvertImageDtype(torch.float),\n",
    "        transforms.Resize((224, 224), interpolation=Image.BICUBIC),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "    ])\n",
    "\n",
    "index = 0\n",
    "with torch.no_grad():\n",
    "    train_dataloader = tqdm(train_dataloader)\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for inputs, labels in train_dataloader:\n",
    "            inputs,labels = inputs.to(device), labels.to(device)\n",
    "            # ============= forward =============\n",
    "            outputs = ResNet50(inputs)\n",
    "            # ============= precision ===========\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            #break\n",
    "            description = 'correct: %.4f, total: %.4f , accuracy: %.4f' % (correct, total, correct/total)\n",
    "            train_dataloader.set_description(description)\n",
    "            train_dataloader.update()\n",
    "print(\"最终结果： \", description)\n",
    "\n",
    "\n",
    "features, labels, ids = [], [], [] # features：提取的2048维图片特征，labels：模型预测的标签，ids图片文件编号\n",
    "\n",
    "feature_model = copy.deepcopy(ResNet50)\n",
    "feature_model.fc = nn.Identity() # 相当于取消fc层, 这样\n",
    "label_model = copy.deepcopy(ResNet50)\n",
    "\n",
    "# 图片路径\n",
    "if dataset_type == \"CIFAR10\":\n",
    "    pic_path = \"./static/data/CIFAR10/pic/random_50k_png\"   \n",
    "\n",
    "img_datasets = Mydata_sets(pic_path, transform=transform)  \n",
    "# img_datasets = torchvision.datasets.CIFAR10(\"./static/data/CIFAR10/\", train=True, download=False, transform=transform) #使用原始的cifar10图片\n",
    "imgLoader = torch.utils.data.DataLoader(img_datasets, batch_size=128, shuffle=False, num_workers=4)  # 指定读取配置信息\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in tqdm(imgLoader):\n",
    "        x = x.to(device)\n",
    "        ids.append(y)  # N\n",
    "        feature = feature_model(x)  # N, 2048\n",
    "        features.append(feature)\n",
    "\n",
    "        ten_D = label_model(x)\n",
    "        label = torch.argmax(ten_D, dim=1)\n",
    "        labels.append(label)\n",
    "\n",
    "features = torch.cat(features, dim=0).squeeze().cpu().numpy()  # (n, 2048)\n",
    "labels = torch.cat(labels, dim=0).squeeze().cpu().numpy()  # n\n",
    "ids = torch.cat(ids, dim=0).cpu().numpy() # n\n",
    "\n",
    "print(features.shape)\n",
    "print(labels.shape)\n",
    "print(ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.6.9 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda:0\")\n",
    "a = torch.load(\"./static/data/CIFAR10/latent_z/BigGAN_random_50k_png_208z_50000.pt\", map_location=device)\n",
    "print(a[0][-128:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.6.9 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "torch.min(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.6.9 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "shared = nn.Embedding(10, 128)\n",
    "shared(torch.tensor(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.6.9 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "def test(lis):\n",
    "    lis[0] = 5\n",
    "\n",
    "def main():\n",
    "    lis = [0]*5\n",
    "    print(lis)\n",
    "    test(lis)\n",
    "    print(lis)\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.6.9 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "\n",
    "# Set the device to CPU or GPU\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Generate a random tensor with a value between 0 and 0.3\n",
    "value = random.uniform(0, 0.3)\n",
    "tensor = torch.tensor(value).unsqueeze(0).to(device)\n",
    "\n",
    "# Print the tensor\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.6.9 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# rob = torch.load(\"./系统以外的资源/对抗鲁棒性PDG/SteeringAngle/ResNet34_regre/PDG_robustness_ResNet34_regre.pt\", map_location=torch.device(\"cpu\"))\n",
    "# rob = torch.load(\"./系统以外的资源/对抗鲁棒性PDG/CIFAR10/ResNet32/PDG_robustness_ResNet32.pt\", map_location=torch.device(\"cpu\"))\n",
    "# rob = torch.load(\"./系统以外的资源/对抗鲁棒性PDG/SteeringAngle/ResNet34_regre/PDG_robustness_ResNet34_regre_wrongAngel=5epsilon=0.0005epsilon_step=0.0005.pt\", map_location=torch.device(\"cpu\"))\n",
    "# rob = torch.load(\"./系统以外的资源/对抗鲁棒性PDG/SteeringAngle/ResNet34_regre/PDG_robustness_ResNet34_regre_wrong angel=8.0epsilon=0.001epsilon_step=0.001.pt\", map_location=torch.device(\"cpu\"))\n",
    "# rob = torch.load(\"./系统以外的资源/对抗鲁棒性PDG/SteeringAngle/ResNet34_regre/PDG_robustness_ResNet34_regre_wrongAngel=5epsilon=0.0002epsilon_step=0.0002.pt\", map_location=torch.device(\"cpu\"))\n",
    "# rob = torch.load(\"./系统以外的资源/对抗鲁棒性PDG/SteeringAngle/ResNet34_regre/PDG_robustness_ResNet34_regre_wrongAngel=10.0epsilon=0.001epsilon_step=0.001.pt\", map_location=torch.device(\"cpu\"))\n",
    "# rob = torch.load(\"./系统以外的资源/对抗鲁棒性PDG/SteeringAngle/ResNet34_regre/PDG_robustness_ResNet34_regre_wrongAngel=15.0epsilon=0.001epsilon_step=0.001.pt\", map_location=torch.device(\"cpu\"))\n",
    "\n",
    "\n",
    "# 创建一个大小为100的随机张量\n",
    "x = torch.tensor(rob)\n",
    "print(x.shape)\n",
    "# 计算直方图及其边界\n",
    "hist, bins = np.histogram(x.numpy(), bins=32, range=(0, 0.032))\n",
    "\n",
    "# 绘制直方图\n",
    "plt.hist(x.numpy(), bins=bins)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.6.9 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import eagerpy as ep\n",
    "import torch\n",
    "\n",
    "# 定义随机张量的形状和数据类型\n",
    "x0 = ep.zeros((3, 3))\n",
    "\n",
    "# 生成服从均匀分布的随机张量\n",
    "epsilon = 0.1\n",
    "rand_tensor = ep.uniform(x0, x0.shape, -epsilon, epsilon)\n",
    "\n",
    "print(rand_tensor)  # 输出一个形状为 (3, 3) 的张量，数据类型为 float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.6.9 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "angles = torch.load(\"./static/data/SteeringAngle/angle/angles_50000.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.6.9 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "print(angles[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.6.9 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# 设置随机数生成器的种子为1\n",
    "random.seed(1)\n",
    "\n",
    "# 生成0到1之间的随机数\n",
    "rand_num_1 = random.random()\n",
    "\n",
    "# 再次生成0到1之间的随机数\n",
    "rand_num_2 = random.random()\n",
    "\n",
    "print(rand_num_1)\n",
    "print(rand_num_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.6.9 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.randrange(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.6.9 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "model_files_dir = \"./model_files/\" # 模型位置\n",
    "sys.path.append(model_files_dir)\n",
    "import model_files as model_all\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.6.9 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "model_files_dir = \"./model_files/\" # 模型位置\n",
    "sys.path.append(model_files_dir)\n",
    "import model_files as model_all\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "def sample_normal(batch_size, z_dim, truncation_factor, device):\n",
    "    if truncation_factor == -1.0:\n",
    "        latents = torch.randn(batch_size, z_dim, device=device)\n",
    "    elif truncation_factor > 0:\n",
    "        latents = torch.FloatTensor(truncated_normal([batch_size, z_dim], truncation_factor)).to(device)\n",
    "    else:\n",
    "        raise ValueError(\"truncated_factor must be positive.\")\n",
    "    return latents\n",
    "def sample_y(y_sampler, batch_size, num_classes, device):\n",
    "    if y_sampler == \"totally_random\":\n",
    "        y_fake = torch.randint(low=0, high=num_classes, size=(batch_size, ), dtype=torch.long, device=device)\n",
    "\n",
    "    elif y_sampler == \"acending_some\":\n",
    "        assert batch_size % 8 == 0, \"The size of batches should be a multiple of 8.\"\n",
    "        num_classes_plot = batch_size // 8\n",
    "        indices = np.random.permutation(num_classes)[:num_classes_plot]\n",
    "\n",
    "    elif y_sampler == \"acending_all\":\n",
    "        batch_size = num_classes * 8\n",
    "        indices = [c for c in range(num_classes)]\n",
    "\n",
    "    elif isinstance(y_sampler, int):\n",
    "        y_fake = torch.tensor([y_sampler] * batch_size, dtype=torch.long).to(device)\n",
    "    else:\n",
    "        y_fake = None\n",
    "\n",
    "    if y_sampler in [\"acending_some\", \"acending_all\"]:\n",
    "        y_fake = []\n",
    "        for idx in indices:\n",
    "            y_fake += [idx] * 8\n",
    "        y_fake = torch.tensor(y_fake, dtype=torch.long).to(device)\n",
    "    return y_fake\n",
    "\n",
    "def sample_zy(z_prior=\"gaussian\", batch_size=80, z_dim=80, num_classes=10, truncation_factor=-1, y_sampler=\"totally_random\", device=device):\n",
    "\n",
    "    fake_labels = sample_y(y_sampler=y_sampler, batch_size=batch_size, num_classes=num_classes, device=device)\n",
    "    batch_size = fake_labels.shape[0]\n",
    "\n",
    "    if z_prior == \"gaussian\":\n",
    "        zs = sample_normal(batch_size=batch_size, z_dim=z_dim, truncation_factor=truncation_factor, device=device)\n",
    "    elif z_prior == \"uniform\":\n",
    "        zs = torch.FloatTensor(batch_size, z_dim).uniform_(-1.0, 1.0).to(device)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    return zs, fake_labels\n",
    "\n",
    "checkpoints_path = \"./model_files/CIFAR10/checkpoints/BigGAN/model=G-best-weights-step=162000.pth\"\n",
    "G = model_all.get_generative_model(\"CIFAR10\").to(device)\n",
    "G.load_state_dict(torch.load(checkpoints_path, map_location=device)[\"state_dict\"])\n",
    "G.eval()\n",
    "\n",
    "zs, labels = sample_zy()\n",
    "fake_images = G(zs, labels)\n",
    "from torchvision.utils import save_image\n",
    "save_image(((fake_images + 1)/2).clamp(0.0, 1.0), \"./test.png\", padding=0, nrow=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.6.9 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.6.9 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.6.9 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.6.9 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "for i in range(3, 10):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.6.9 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.tensor([4,6,4])\n",
    "b = torch.tensor([2,2,2])\n",
    "\n",
    "a * b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.6.9 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "os.environ[\"GIT_PYTHON_REFRESH\"] = \"quiet\"\n",
    "from foolbox import PyTorchModel, accuracy, samples\n",
    "from foolbox.attacks import LinfPGD\n",
    "import csv\n",
    "\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import model_files as model_all #模型的连接在__init__.py中体现\n",
    "\n",
    "import argparse\n",
    "\n",
    "'''\n",
    "arg主要是模型选择参数\n",
    "'''\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--dataset', type=str, default=\"CIFAR10\", help=\"数据集类别: CIFAR10或者MNIST\")\n",
    "parser.add_argument('--model_name', type=str, default=\"ResNet20\", help=\"模型名字，例如ResNet20\")\n",
    "parser.add_argument('--weight_dir', type=str, default=\"./model_files/CIFAR10/checkpoints/classify_model/\", help=\"模型参数的位置\")\n",
    "parser.add_argument('--epoch', type=str, default='199', help=\"决定用那个epoch的模型参数\")\n",
    "parser.add_argument('--gpu_id', type=str, default='0')\n",
    "args = parser.parse_args()\n",
    "\n",
    "# 设备检测\n",
    "device = torch.device(\"cuda:\" + args.gpu_id  if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = model_all.get_DNN_model(args.dataset,args.model_name)\n",
    "model.load_state_dict(torch.load(args.weight_dir + args.model_name + '.pt'))\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "#读取数据\n",
    "pic_path = \"./static/data/\"+ args.dataset +\"/pic/random_50k\"\n",
    "filenames = os.listdir(pic_path)\n",
    "filenames.sort(key=lambda x: int(x[4:-4])) # pic_0.jpg,根据编号进行排序\n",
    "\n",
    "\n",
    "if args.dataset == \"MNIST\":\n",
    "    transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Resize([32,32])\n",
    "            ]\n",
    "        )\n",
    "    preprocessing = dict(mean=[0.5], std=[0.5], axis=-3)\n",
    "elif args.dataset == \"CIFAR10\":\n",
    "    transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.4914,0.4822,0.4465], [0.2023,0.1994,0.2010])\n",
    "            ]\n",
    "        )\n",
    "    preprocessing = dict(mean=[0.4914,0.4822,0.4465], std=[0.2023,0.1994,0.2010], axis=-3)\n",
    "\n",
    "\n",
    "fmodel = PyTorchModel(model, bounds=(0, 1), device = device, preprocessing=preprocessing)\n",
    "attack = LinfPGD()\n",
    "arr=[]\n",
    "\n",
    "#数据\n",
    "robustness = []\n",
    "for i, file in enumerate(filenames):\n",
    "    position = pic_path + \"/\" + file\n",
    "    if args.dataset == \"MNIST\":\n",
    "        image = Image.open(position).convert('L')\n",
    "    elif args.dataset == \"CIFAR10\":\n",
    "        image = Image.open(position)\n",
    "    input_image = transform(image)\n",
    "    input_image = input_image.unsqueeze(0).to(device)  # 增加一个维度维batch维度\n",
    "    print(\"image.shape:\",input_image.shape)\n",
    "    output = model(input_image)\n",
    "    print(output)\n",
    "    a = input(\"press 0 to break: \")\n",
    "    if a == \"0\":\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.6.9 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os \n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import codecs\n",
    "import model_files as model_all #模型的连接在__init__.py中体现\n",
    "from PIL import Image \n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "pic_path = \"./static/data/CIFAR10/pic/random_50k\"\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.4914,0.4822,0.4465], [0.2023,0.1994,0.2010])])\n",
    "robustness = torch.load(\"./系统以外的资源/对抗鲁棒性PDG/CIFAR10/ResNet20/PDG_robustness_ResNet20.pt\")\n",
    "\n",
    "class Mydata_sets(Dataset):\n",
    "    \n",
    "    def __init__(self, pic_path, pic_robustness, train, transform):\n",
    "        super(Mydata_sets, self).__init__()\n",
    "        self.root_dir = pic_path\n",
    "        self.transform = transform\n",
    "        filenames = os.listdir(pic_path)\n",
    "        filenames.sort(key=lambda x: int(x[4:-4])) # pic_0.jpg,根据编号进行排序\n",
    "        if(train == True):\n",
    "            self.pic_filenames = filenames[:40000]\n",
    "            self.pic_robustness = pic_robustness[:40000]\n",
    "        else:\n",
    "            self.pic_filenames = filenames[40000:]\n",
    "            self.pic_robustness = pic_robustness[40000:]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_name = self.pic_filenames[index]\n",
    "        img = Image.open(os.path.join(self.root_dir, img_name))\n",
    "        img = self.transform(img)\n",
    "        pic_robustness = self.pic_robustness[index]\n",
    "        return img, pic_robustness\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pic_filenames)\n",
    "\n",
    "\n",
    "#读取模型数据\n",
    "model = model_all.get_DNN_model(\"CIFAR10\",\"ResNet20\")\n",
    "model.load_state_dict(torch.load(\"./model_files/CIFAR10/checkpoints/classify_model/ResNet20.pt\"))\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "\n",
    "test_dataloader = DataLoader(Mydata_sets(pic_path, robustness, False, transform = transform), batch_size=3, shuffle=False)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, robs) in enumerate(test_dataloader):\n",
    "        inputs, robs = inputs.to(device),torch.tensor(robs).to(torch.float32).to(device)\n",
    "        # =========== forward ==========\n",
    "        penultimate_layer = model(inputs)\n",
    "\n",
    "        print(\"penultimate_layer: \", penultimate_layer)\n",
    "        a = input(\"press 0 to break: \")\n",
    "        if a == \"0\":\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.6.9 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 定义嵌入层\n",
    "embedding = nn.Embedding(num_embeddings=100, embedding_dim=50)\n",
    "\n",
    "# 定义输入序列\n",
    "input_seq = torch.tensor([1, 1, 3, 4, 5])\n",
    "\n",
    "# 将输入序列映射为嵌入向量\n",
    "embedded_seq = embedding(input_seq)\n",
    "\n",
    "# 输出嵌入向量\n",
    "print(embedded_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.6.9 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial import KDTree\n",
    "points = np.array([(0, 0), (1, 0), (0, 1), (1, 1)])\n",
    "\n",
    "# 创建 KD 树\n",
    "tree = KDTree(points)\n",
    "tree.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.6.9 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 定义两个向量\n",
    "v1 = np.array([0,0])\n",
    "v2 = np.array([1,2])\n",
    "\n",
    "# 计算两个向量之间的距离\n",
    "distance = np.linalg.norm(v1 - v2)\n",
    "\n",
    "print(\"向量 v1 和向量 v2 之间的距离为：\", distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.6.9 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial import KDTree\n",
    "\n",
    "# 创建一个二维数据集\n",
    "points = np.array([(0, 0), (1, 0), (0, 1), (1, 1)])\n",
    "\n",
    "# 创建 KD 树\n",
    "tree = KDTree(points)\n",
    "\n",
    "# 获取距离指定点最近的点及其距离\n",
    "query_point = np.array([(0.5, 0.5)])\n",
    "dist, ind = tree.query(query_point,k=2)\n",
    "nearest_point = points[ind]\n",
    "print(\"距离最近的点：\", nearest_point)\n",
    "print(\"距离：\", dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.6.9 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "\n",
    "device = torch.device(\"cuda:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.6.9 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# state_dict = torch.load(\"cifar10_resnet20.pt\", map_location=device)\n",
    "# model = ResNet.CifarResNet().to(device)\n",
    "# model.load_state_dict(state_dict)\n",
    "\n",
    "import torch\n",
    "model = torch.hub.load(\"chenyaofo/pytorch-cifar-models\", \"cifar10_resnet20\", pretrained=True)\n",
    "model.eval()\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.6.9 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.4914,0.4822,0.4465], [0.2023,0.1994,0.2010])]) #CIFAR10数据集的均值和方差，多处网络验证\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.4914,0.4822,0.4465], [0.2023,0.1994,0.2010])])\n",
    "train_dataloader = DataLoader(datasets.CIFAR10('./static/data/CIFAR10/CIFAR10', train=True, download=True, transform=transform), batch_size=128, shuffle=True)\n",
    "test_dataloader = DataLoader(datasets.CIFAR10('./static/data/CIFAR10/CIFAR10', train=False, download=True, transform=transform), batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.6.9 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "test_dataloader = tqdm(test_dataloader)\n",
    "total = 0\n",
    "correct = 0\n",
    "for inputs, labels in test_dataloader:\n",
    "    inputs,labels = inputs.to(device),labels.to(device)\n",
    "    # ============= forward =============\n",
    "    outputs = model(inputs)\n",
    "    # ============= precision ===========\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "    description = '【测试集】correct: %.4f, total: %.4f , accuracy: %.4f' % (correct, total, correct/total)\n",
    "    test_dataloader.set_description(description)\n",
    "    test_dataloader.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.6.9 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "import foolbox\n",
    "import model_files as model_all #模型的连接在__init__.py中体现\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "dataset=\"CIFAR10\"\n",
    "model_name=\"ResNet20\"\n",
    "weight_dir=\"./model_files/CIFAR10/checkpoints/classify_model/\"\n",
    "device = torch.device(\"cuda:0\")\n",
    "# 加载模型\n",
    "model = model_all.get_DNN_model(dataset, model_name)\n",
    "model.load_state_dict(torch.load(weight_dir + model_name + '.pt', map_location=\"cpu\"))\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# 加载图像并预处理\n",
    "pic_path = \"./static/data/\"+ dataset +\"/pic/random_50k/pic_1.jpg\"\n",
    "image= Image.open(pic_path)\n",
    "label=torch.tensor(6).unsqueeze(0).to(device)\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "preprocessing = dict(mean=[0.4914,0.4822,0.4465], std=[0.2023,0.1994,0.2010], axis=-3)\n",
    "image = preprocess(image).to(device)\n",
    "image = image.unsqueeze(0)  # 将图像增加一个维度，变成4D张量\n",
    "\n",
    "# 创建一个Foolbox模型\n",
    "fmodel = foolbox.models.PyTorchModel(model, bounds=(0, 1), preprocessing=preprocessing)\n",
    "\n",
    "# 计算模型在给定图像上的鲁棒性\n",
    "attack = foolbox.attacks.LinfPGD()\n",
    "adversarials = attack(fmodel, image, label, epsilons=[0.1, 0.2, 0.3])\n",
    "\n",
    "labels = np.argmax(fmodel(image).cpu())\n",
    "adv_labels=[]\n",
    "print(adversarials)\n",
    "for adv in adversarials:\n",
    "    adv_labels.append(np.argmax(fmodel(adv)))\n",
    "robustness = np.mean(adv_labels == labels)\n",
    "\n",
    "# 输出结果\n",
    "print(f\"Robustness: {robustness:.2%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('python3_7')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f3f0160846dacded17c5b67f58dcaec22223f12fd996fcee9cc72ae8f24d8129"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
