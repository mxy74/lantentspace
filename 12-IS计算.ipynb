{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "dataset_type = \"CIFAR10\"\n",
    "sample_2D = False\n",
    "sample_208D = True\n",
    "save_origin_pic = False\n",
    "\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 是否保存原始图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as utils\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "if save_origin_pic == True:\n",
    "    number = 50000\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    train_dataloader = DataLoader(datasets.CIFAR10('./static/data/CIFAR10/CIFAR10', train=True, download=True, transform=transform), batch_size=1, shuffle=False)\n",
    "    save_path = './static/data/CIFAR10/pic/origin_50k_png/'\n",
    "\n",
    "    index = 0\n",
    "    for data in train_dataloader:\n",
    "        img, labels = data\n",
    "        utils.save_image(img, save_path + 'pic_' + str(index) + '.png', nrow=1)\n",
    "        index += 1\n",
    "        if index >= number:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 是否从原始空间中采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存tensor，不保存图片\n",
    "# import sys\n",
    "# python_files_dir = \"./python_files/\" # python工具包位置\n",
    "# sys.path.append(python_files_dir)\n",
    "# import my_tools\n",
    "# import fid_score as official_fid\n",
    "\n",
    "# model_files_dir = \"./model_files/\" # 模型位置\n",
    "# sys.path.append(model_files_dir)\n",
    "# import model_files as all_model\n",
    "\n",
    "# from CIFAR10.models import ResNet20 as classify_model\n",
    "# from CIFAR10.models import Rob_predictor as my_Rob_predictor\n",
    "# from CIFAR10.models import BigGAN\n",
    "\n",
    "# from tqdm import tqdm\n",
    "# import numpy as np\n",
    "# import random\n",
    "# import torchvision.utils as utils\n",
    "\n",
    "# if sample_208D:\n",
    "#     # 选择生成模型\n",
    "#     checkpoints_path = \"./model_files/CIFAR10/checkpoints/BigGAN/model=G-best-weights-step=132000.pth\"\n",
    "#     G = BigGAN.Generator().to(device)\n",
    "#     G.load_state_dict(torch.load(checkpoints_path, map_location=device)[\"state_dict\"])\n",
    "#     G.eval()\n",
    "#     number = 50000\n",
    "\n",
    "    \n",
    "#     for num in tqdm(range(number)):\n",
    "#         z = torch.tensor(np.random.RandomState(num).randn(1, 80)).to(torch.float32).to(device)    # latent code\n",
    "#         label = torch.tensor(random.randrange(10)).unsqueeze(0).to(device)\n",
    "#         shared_label = G.shared(label)\n",
    "#         z_and_shared_label = torch.cat((z, shared_label), dim = 1)\n",
    "#         if num == 0:\n",
    "#             z_and_shared_labels = z_and_shared_label\n",
    "#         else:\n",
    "#             z_and_shared_labels = torch.cat((z_and_shared_labels, z_and_shared_label))\n",
    "#         img = G(z = z_and_shared_label)                           # NCHW, float32, dynamic range [-1, +1]\n",
    "#         torch.save(img, \"./static/data/CIFAR10/pic/random_50k_tensor/pic_\" + str(num) + '.pyt')\n",
    "\n",
    "#     torch.save(z_and_shared_labels, './static/data/CIFAR10/latent_z/BigGAN_random_50k_tensor_208z_' + str(number) + '.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [06:47<00:00, 122.59it/s]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "python_files_dir = \"./python_files/\" # python工具包位置\n",
    "sys.path.append(python_files_dir)\n",
    "import fid_score as official_fid\n",
    "\n",
    "model_files_dir = \"./model_files/\" # 模型位置\n",
    "sys.path.append(model_files_dir)\n",
    "import model_files as all_model\n",
    "\n",
    "from CIFAR10.models import ResNet20 as classify_model\n",
    "from CIFAR10.models import Rob_predictor as my_Rob_predictor\n",
    "from CIFAR10.models import BigGAN\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "import torchvision.utils as utils\n",
    "\n",
    "if sample_208D:\n",
    "    # 选择生成模型\n",
    "    checkpoints_path = \"./model_files/CIFAR10/checkpoints/BigGAN/model=G-best-weights-step=392000.pth\"\n",
    "    G = BigGAN.Generator().to(device)\n",
    "    G.load_state_dict(torch.load(checkpoints_path, map_location=device)[\"state_dict\"])\n",
    "    G.eval()\n",
    "    number = 50000\n",
    "\n",
    "    save_pic_path = \"./static/data/CIFAR10/pic/random_50k_png\"\n",
    "    \n",
    "    for num in tqdm(range(number)):\n",
    "        z = torch.tensor(np.random.RandomState(num).randn(1, 80)).to(torch.float32).to(device)    # latent code\n",
    "        label = torch.tensor(random.randrange(10)).unsqueeze(0).to(device)\n",
    "        shared_label = G.shared(label)\n",
    "        z_and_shared_label = torch.cat((z, shared_label), dim = 1)\n",
    "        if num == 0:\n",
    "            z_and_shared_labels = z_and_shared_label\n",
    "            labels = label\n",
    "        else:\n",
    "            z_and_shared_labels = torch.cat((z_and_shared_labels, z_and_shared_label))\n",
    "            labels = torch.cat((labels, label), dim=0)\n",
    "        img = G(z = z_and_shared_label)                           # NCHW, float32, dynamic range [-1, +1]\n",
    "        img = ((img + 1)/2).clamp(0.0, 1.0) # 变换到[0,1]范围内\n",
    "        # print(z.shape) # [1, 80]\n",
    "        # print(shared_label.shape) # [1, 128]\n",
    "        # print(z_and_shared_label.shape) # [1, 208]\n",
    "        utils.save_image(img.detach().cpu(), save_pic_path + '/pic_' + str(num) + '.png')\n",
    "    import datetime\n",
    "    date_time = datetime.date.today()\n",
    "    torch.save(z_and_shared_labels, f'./static/data/CIFAR10/latent_z/BigGAN_random_png_208z_{number}_{date_time}.pt')\n",
    "    torch.save(labels, f'./static/data/CIFAR10/labels/BigGAN_random_png_208z_{number}_{date_time}_labels.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 是否从2D空间中采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.utils as utils\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import torch\n",
    "\n",
    "# 插值函数\n",
    "def get_zs_prevent_stick(coordinates, kdTree_2D, latent_z, k=10):\n",
    "    '''\n",
    "    nearest_distance: n*k维\n",
    "    nearest_index: n*k维\n",
    "    dict_zs: 键是文件的id号, 值是对应的z（后面直接改成数组了，问题不大）\n",
    "    '''\n",
    "    print(\"进入了防止粘在一块~~~~~~~~~~~~~~~~~~\")\n",
    "    # 直接一次查询所有坐标的k个近邻\n",
    "    nearest_distance, nearest_index = kdTree_2D.query(coordinates, k=k)\n",
    "    origin_coordinates = kdTree_2D.data # 获取kdtree中原始的坐标\n",
    "    for i, pos in enumerate(coordinates): #对每一个坐标进行插值\n",
    "        # pos坐标对应的近邻下标\n",
    "        pos_nearst_index = nearest_index[i] # 其中有k个index，每个index对应kdTree_2D中的一个2维坐标\n",
    "        pos_nearst_distance = nearest_distance[i]\n",
    "\n",
    "        # 最近邻的坐标点，以及最近的距离\n",
    "        most_nearst_pos = origin_coordinates[pos_nearst_index[0]]\n",
    "        most_nearst_dis = pos_nearst_distance[0]\n",
    "\n",
    "        # 利用三角形,找到第二个插值基点，让两边之和越接近第三边，就越是钝角，就越合理\n",
    "        s1 = most_nearst_dis\n",
    "        best_index = 1 # 默认第二个最近邻最好\n",
    "        min_dif = 100\n",
    "        for j in range(1, k):\n",
    "            cur_pos = origin_coordinates[pos_nearst_index[j]]\n",
    "            s2 = pos_nearst_distance[j]\n",
    "            s3 = np.linalg.norm(most_nearst_pos-cur_pos)\n",
    "            if (s1 + s2) - s3 < min_dif: # 两边之和大于等于第三边，所以不用绝对值\n",
    "                min_dif = (s1 + s2) - s3\n",
    "                best_index = j\n",
    "        \n",
    "        temp_z_0 = latent_z[pos_nearst_index[0]].clone().detach()\n",
    "        temp_z_1 = latent_z[pos_nearst_index[best_index]].clone().detach()\n",
    "        sum_distance = most_nearst_dis + pos_nearst_distance[best_index]\n",
    "        z_new = (sum_distance-most_nearst_dis)/(sum_distance) * temp_z_0 + (sum_distance-pos_nearst_distance[best_index])/(sum_distance) * temp_z_1\n",
    "\n",
    "        z_new = z_new.unsqueeze(0)\n",
    "        if i == 0:\n",
    "            zs = z_new\n",
    "        else:\n",
    "            zs = torch.cat((zs, z_new), dim=0)\n",
    "\n",
    "    return zs\n",
    "\n",
    "\n",
    "# 最开始的版本，就取近邻的向量进行插值，但是不对类的向量进行插值\n",
    "def get_zs_new_not_class(coordinates, kdTree_2D, latent_z, k=20):\n",
    "    '''\n",
    "    coordinates: n个要插值的坐标\n",
    "    kdTree_2D: 降维后的2D坐标\n",
    "    latent_z: 生成模型的输入潜向量，和kdTree_2D是一一对应关系\n",
    "    k: 近邻的数量\n",
    "    '''\n",
    "    print(\"最开始的版本，优化了一下代码~~~~~~~~~~~ k:\",k)\n",
    "    # 直接一次查询所有坐标的k个近邻\n",
    "    nearest_distance, nearest_index = kdTree_2D.query(coordinates, k=k) #这里的k为固定值\n",
    "    origin_coordinates = kdTree_2D.data # 获取kdtree中原始的坐标\n",
    "    for iter in range(len(coordinates)):\n",
    "        iter_distance = nearest_distance[iter]\n",
    "        iter_index = nearest_index[iter]\n",
    "        \n",
    "        sum_distanceForIter = np.sum(iter_distance) #这k个近邻的距离总和\n",
    "        for i, index in enumerate(iter_index):\n",
    "            temp_z = torch.tensor(latent_z[index])\n",
    "            temp_distance = iter_distance[i]\n",
    "            w = (sum_distanceForIter-temp_distance)/((k-1)*sum_distanceForIter) #对z进行权重\n",
    "            if i == 0:\n",
    "                z = temp_z*w\n",
    "            else:\n",
    "                z += temp_z*w\n",
    "\n",
    "        z[-128:] = latent_z[iter_index[0]][-128:]   #类向量为最近的那一个点的向量\n",
    "\n",
    "        z = z.unsqueeze(0) # shape:[1*latent_dim]\n",
    "        if iter == 0:\n",
    "            zs = z\n",
    "        else:\n",
    "            zs = torch.cat((zs, z), dim=0)\n",
    "        # print(zs.shape)\n",
    "    return zs\n",
    "\n",
    "\n",
    "# 用来处理zs的类，方便使用batchsize\n",
    "class Mydata_sets(Dataset):\n",
    "    \n",
    "    def __init__(self, zs):\n",
    "        super(Mydata_sets, self).__init__()\n",
    "        self.zs = zs\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        z = self.zs[index]\n",
    "        return z\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.zs)\n",
    "\n",
    "if sample_2D:\n",
    "    \n",
    "    # 读取二维坐标数据\n",
    "    kdTree = torch.load(\"./static/data/CIFAR10/2D_kdTree/2D_kdTree_50000_png.pt\")\n",
    "    coords = kdTree.data\n",
    "\n",
    "    # 计算坐标点的协方差矩阵\n",
    "    cov = np.cov(coords.T)\n",
    "\n",
    "    # 生成符合多元正态分布的新坐标点\n",
    "    new_coords = np.random.multivariate_normal(np.mean(coords, axis=0), cov, size=50000)\n",
    "\n",
    "    latent_z_path=\"./static/data/CIFAR10/latent_z/BigGAN_random_50k_png_208z_50000.pt\"\n",
    "    latent_z = torch.load(latent_z_path, map_location=\"cpu\") #因为我之前保存数据到了GPU上，所以要回到cpu上才不会出错    \n",
    "\n",
    "    # from scipy import spatial\n",
    "    # norm_tree =  spatial.KDTree(data=new_coords)\n",
    "\n",
    "    zs = get_zs_prevent_stick(new_coords, kdTree, latent_z)\n",
    "\n",
    "    zs_datasets = Mydata_sets(zs)\n",
    "    zs_loader = DataLoader(zs_datasets, batch_size=200, shuffle=False, num_workers=1)\n",
    "\n",
    "    model_files_dir = \"./model_files/\" # 模型位置\n",
    "    sys.path.append(model_files_dir)\n",
    "    import model_files as model_all\n",
    "    checkpoints_path = \"./model_files/CIFAR10/checkpoints/BigGAN/model=G-best-weights-step=392000.pth\"\n",
    "    G = model_all.get_generative_model(\"CIFAR10\").to(device)\n",
    "    G.load_state_dict(torch.load(checkpoints_path, map_location=device)[\"state_dict\"])\n",
    "    G.eval()\n",
    "\n",
    "    first = 0 # 判断是否第一次进入循环\n",
    "    count = 0\n",
    "    with torch.no_grad(): # 取消梯度计算，加快运行速度\n",
    "        for batch_z in zs_loader: \n",
    "            z = torch.tensor(batch_z).to(torch.float32).to(device)    # latent code\n",
    "            imgs = G(z)   \n",
    "            for i, img in enumerate(imgs):\n",
    "                img = ((img + 1)/2).clamp(0.0, 1.0) # 变换到[0,1]范围内\n",
    "                utils.save_image(img.detach().cpu(), f'./static/data/CIFAR10/pic/2D_50k_png/pic_{count}.png')\n",
    "                count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 自定义dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image \n",
    "\n",
    "class Mydata_sets(Dataset):\n",
    "    \n",
    "    def __init__(self, path, transform=None):\n",
    "        super(Mydata_sets, self).__init__()\n",
    "        self.root_dir = path\n",
    "        self.img_names = os.listdir(self.root_dir)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_name = self.img_names[index]\n",
    "        img = Image.open(os.path.join(self.root_dir, img_name))\n",
    "        id_name = torch.tensor(int(img_name[4:-4])) #pic_xx.jpg\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img, id_name\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_names)\n",
    "\n",
    "# # 直接读取tensor数据\n",
    "# class Mydata_sets2(Dataset):\n",
    "    \n",
    "#     def __init__(self, path, transform):\n",
    "#         super(Mydata_sets2, self).__init__()\n",
    "#         self.root_dir = path\n",
    "#         self.img_names = os.listdir(self.root_dir)\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         img_name = self.img_names[index]\n",
    "#         img = torch.load(os.path.join(self.root_dir, img_name), map_location=device)\n",
    "#         id_name = torch.tensor(int(img_name[4:-4])) #pic_xx.jpg\n",
    "\n",
    "#         return img, id_name\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.img_names)\n",
    "\n",
    "if dataset_type == \"CIFAR10\":\n",
    "    # transform = transforms.Compose([\n",
    "    #     transforms.Resize((299, 299), interpolation=Image.BICUBIC),\n",
    "    #     transforms.ToTensor(),\n",
    "    #     transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "    # ])\n",
    "    # transform = transforms.Compose([\n",
    "    #     transforms.Resize((299, 299)),\n",
    "    #     transforms.ToTensor(),\n",
    "    #     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    # ])\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "    ])\n",
    "    # transform = transforms.Compose([\n",
    "    #     transforms.ToTensor(),\n",
    "    #     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    # ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 开始计算is值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 使用vgg_19获取\n",
    "# python_files_dir = \"./python_files/\" # python工具包位置\n",
    "# sys.path.append(python_files_dir)\n",
    "\n",
    "# model_files_dir = \"./model_files/\" # 模型位置\n",
    "# sys.path.append(model_files_dir)\n",
    "# import model_files as model_all\n",
    "\n",
    "# inception_model = model_all.get_DNN_model(dataset_type, \"VGG19_BN\")\n",
    "# inception_model.load_state_dict(torch.load(\"./model_files/\" + dataset_type + \"/checkpoints/classify_model/VGG19_BN.pt\", map_location=device))\n",
    "# inception_model.eval()\n",
    "# inception_model.to(device)\n",
    "\n",
    "# # 生成的图像数据集\n",
    "# generated_dataset = Mydata_sets(path=\"./static/data/CIFAR10/pic/random_50k/\",transform=transform)\n",
    "# generated_dataloader = DataLoader(generated_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# # 计算预测分数\n",
    "# predictions = []\n",
    "# for images, ids in generated_dataloader:\n",
    "#     images = images.to(device)\n",
    "#     with torch.no_grad():\n",
    "#         preds = inception_model(images)\n",
    "#     predictions.append(torch.softmax(preds, dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用inception_v3获取\n",
    "from torchvision.models import inception_v3\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 加载预训练的Inception模型\n",
    "inception_model = inception_v3(pretrained=True, transform_input=False).eval()\n",
    "device = torch.device(\"cuda:1\")\n",
    "inception_model.to(device)\n",
    "\n",
    "\n",
    "# 生成的图像数据集（假设你有一个名为generated_data的数据集）\n",
    "generated_dataset = Mydata_sets(path=\"./static/data/CIFAR10/pic/random_50k_png/\",transform=transform)\n",
    "generated_dataloader = DataLoader(generated_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# 计算预测分数\n",
    "predictions = []\n",
    "for images, ids in generated_dataloader:\n",
    "    images = images.to(device)\n",
    "    with torch.no_grad():\n",
    "        images = F.interpolate(images, size=(299, 299), mode='bilinear', align_corners=False)\n",
    "        preds = inception_model(images)\n",
    "    predictions.append(torch.softmax(preds, dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用inception_v3获取cifar10原始数据集的\n",
    "# from torchvision.models import inception_v3\n",
    "# import torchvision.datasets as datasets\n",
    "# from torch.utils.data import DataLoader\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# # 加载预训练的Inception模型\n",
    "# inception_model = inception_v3(pretrained=True, transform_input=False).eval()\n",
    "# device = torch.device(\"cuda:1\")\n",
    "# inception_model.to(device)\n",
    "\n",
    "\n",
    "# # 生成的图像数据集（假设你有一个名为generated_data的数据集）\n",
    "# train_dataset = datasets.CIFAR10(root = './static/data/CIFAR10/CIFAR10', train= True, transform=transform)\n",
    "# train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# # 计算预测分数\n",
    "# predictions = []\n",
    "# for images, ids in train_dataloader:\n",
    "#     images = images.to(device)\n",
    "#     with torch.no_grad():\n",
    "#         images = F.interpolate(images, size=(299, 299), mode='bilinear', align_corners=False)\n",
    "#         preds = inception_model(images)\n",
    "#     predictions.append(torch.softmax(preds, dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions.shape:  torch.Size([50000, 1000])\n"
     ]
    }
   ],
   "source": [
    "predictions = torch.cat(predictions, dim=0)\n",
    "print(\"predictions.shape: \", predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50000])\n",
      "Inception Score: 8.732325553894043\n"
     ]
    }
   ],
   "source": [
    "fake_probs = predictions\n",
    "# fake_probs.mean(dim=0, keepdim=True).shape\n",
    "# 计算Inception Score\n",
    "kl_divergence = (fake_probs * (fake_probs / fake_probs.mean(dim=0, keepdim=True)).log()).sum(dim=1)\n",
    "print(kl_divergence.shape)\n",
    "inception_score = torch.exp(kl_divergence.mean()).item()\n",
    "print(\"Inception Score:\", inception_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 计算fid值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fid_model load success!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:50<00:00,  9.94it/s]\n",
      "100%|██████████| 500/500 [00:50<00:00,  9.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma1.shape:  (2048, 2048)\n",
      "sigma2.shape:  (2048, 2048)\n",
      "14.653057963345361\n"
     ]
    }
   ],
   "source": [
    "# fid计算模型\n",
    "dims = 2048\n",
    "batch_size = 1\n",
    "num_avail_cpus = len(os.sched_getaffinity(0))\n",
    "num_workers = min(num_avail_cpus, 8)\n",
    "block_idx = official_fid.InceptionV3.BLOCK_INDEX_BY_DIM[2048]\n",
    "fid_model = official_fid.InceptionV3([block_idx], normalize_input=False).to(device)\n",
    "# fid_model = official_fid.InceptionV3([block_idx]).to(device)\n",
    "print('fid_model load success!')\n",
    "\n",
    "if dataset_type == \"CIFAR10\":\n",
    "    pic_path_fid1 = './static/data/CIFAR10/pic/origin_50k_png'\n",
    "    pic_path_fid2 = './static/data/CIFAR10/pic/2D_50k_png'\n",
    "\n",
    "    \n",
    "batch_size = 100\n",
    "m1, s1 = official_fid.compute_statistics_of_path(pic_path_fid1, fid_model, batch_size,\n",
    "                                    dims, device, num_workers)\n",
    "m2, s2 = official_fid.compute_statistics_of_path(pic_path_fid2, fid_model, batch_size,\n",
    "                                    dims, device, num_workers)\n",
    "fid_value=official_fid.calculate_frechet_distance(m1,s1,m2,s2) \n",
    "print(fid_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('python3_7')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f3f0160846dacded17c5b67f58dcaec22223f12fd996fcee9cc72ae8f24d8129"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
