{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "dataset_type = \"CIFAR10\"\n",
    "sample_2D = True\n",
    "sample_208D = False\n",
    "save_origin_pic = False\n",
    "\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 是否从2D空间中采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.utils as utils\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import torch\n",
    "\n",
    "# 插值函数\n",
    "def get_zs_prevent_stick(coordinates, kdTree_2D, latent_z, k=10):\n",
    "    '''\n",
    "    nearest_distance: n*k维\n",
    "    nearest_index: n*k维\n",
    "    dict_zs: 键是文件的id号, 值是对应的z（后面直接改成数组了，问题不大）\n",
    "    '''\n",
    "    print(\"进入了防止粘在一块~~~~~~~~~~~~~~~~~~\")\n",
    "    # 直接一次查询所有坐标的k个近邻\n",
    "    nearest_distance, nearest_index = kdTree_2D.query(coordinates, k=k)\n",
    "    origin_coordinates = kdTree_2D.data # 获取kdtree中原始的坐标\n",
    "    for i, pos in enumerate(coordinates): #对每一个坐标进行插值\n",
    "        # pos坐标对应的近邻下标\n",
    "        pos_nearst_index = nearest_index[i] # 其中有k个index，每个index对应kdTree_2D中的一个2维坐标\n",
    "        pos_nearst_distance = nearest_distance[i]\n",
    "\n",
    "        # 最近邻的坐标点，以及最近的距离\n",
    "        most_nearst_pos = origin_coordinates[pos_nearst_index[0]]\n",
    "        most_nearst_dis = pos_nearst_distance[0]\n",
    "\n",
    "        # 利用三角形,找到第二个插值基点，让两边之和越接近第三边，就越是钝角，就越合理\n",
    "        s1 = most_nearst_dis\n",
    "        best_index = 1 # 默认第二个最近邻最好\n",
    "        min_dif = 100\n",
    "        for j in range(1, k):\n",
    "            cur_pos = origin_coordinates[pos_nearst_index[j]]\n",
    "            s2 = pos_nearst_distance[j]\n",
    "            s3 = np.linalg.norm(most_nearst_pos-cur_pos)\n",
    "            if (s1 + s2) - s3 < min_dif: # 两边之和大于等于第三边，所以不用绝对值\n",
    "                min_dif = (s1 + s2) - s3\n",
    "                best_index = j\n",
    "        \n",
    "        temp_z_0 = latent_z[pos_nearst_index[0]].clone().detach()\n",
    "        temp_z_1 = latent_z[pos_nearst_index[best_index]].clone().detach()\n",
    "        sum_distance = most_nearst_dis + pos_nearst_distance[best_index]\n",
    "        z_new = (sum_distance-most_nearst_dis)/(sum_distance) * temp_z_0 + (sum_distance-pos_nearst_distance[best_index])/(sum_distance) * temp_z_1\n",
    "\n",
    "        z_new = z_new.unsqueeze(0)\n",
    "        if i == 0:\n",
    "            zs = z_new\n",
    "        else:\n",
    "            zs = torch.cat((zs, z_new), dim=0)\n",
    "\n",
    "    return zs\n",
    "\n",
    "\n",
    "# 用来处理zs的类，方便使用batchsize\n",
    "class Mydata_sets(Dataset):\n",
    "    \n",
    "    def __init__(self, zs):\n",
    "        super(Mydata_sets, self).__init__()\n",
    "        self.zs = zs\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        z = self.zs[index]\n",
    "        return z\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.zs)\n",
    "\n",
    "if sample_2D:\n",
    "    \n",
    "    # 读取二维坐标数据\n",
    "    kdTree = torch.load(\"./static/data/CIFAR10/2D_kdTree/2D_kdTree_50000_png.pt\")\n",
    "    coords = kdTree.data\n",
    "\n",
    "    # 计算坐标点的协方差矩阵\n",
    "    cov = np.cov(coords.T)\n",
    "\n",
    "    # 生成符合多元正态分布的新坐标点\n",
    "    new_coords = np.random.multivariate_normal(np.mean(coords, axis=0), cov, size=50000)\n",
    "\n",
    "    latent_z_path=\"./static/data/CIFAR10/latent_z/BigGAN_random_50k_png_208z_50000.pt\"\n",
    "    latent_z = torch.load(latent_z_path, map_location=\"cpu\") #因为我之前保存数据到了GPU上，所以要回到cpu上才不会出错    \n",
    "\n",
    "    from scipy import spatial\n",
    "    norm_tree =  spatial.KDTree(data=new_coords)\n",
    "\n",
    "    zs = get_zs_prevent_stick(new_coords, kdTree, latent_z)\n",
    "\n",
    "    zs_datasets = Mydata_sets(zs)\n",
    "    zs_loader = DataLoader(zs_datasets, batch_size=200, shuffle=False, num_workers=1)\n",
    "\n",
    "    model_files_dir = \"./model_files/\" # 模型位置\n",
    "    sys.path.append(model_files_dir)\n",
    "    import model_files as model_all\n",
    "    checkpoints_path = \"./model_files/CIFAR10/checkpoints/BigGAN/model=G-best-weights-step=392000.pth\"\n",
    "    G = model_all.get_generative_model(\"CIFAR10\").to(device)\n",
    "    G.load_state_dict(torch.load(checkpoints_path, map_location=device)[\"state_dict\"])\n",
    "    G.eval()\n",
    "\n",
    "    first = 0 # 判断是否第一次进入循环\n",
    "    count = 0\n",
    "    with torch.no_grad(): # 取消梯度计算，加快运行速度\n",
    "        for batch_z in zs_loader: \n",
    "            z = torch.tensor(batch_z).to(torch.float32).to(device)    # latent code\n",
    "            imgs = G(z)   \n",
    "            for i, img in enumerate(imgs):\n",
    "                img = ((img + 1)/2).clamp(0.0, 1.0) # 变换到[0,1]范围内\n",
    "                utils.save_image(img.detach().cpu(), f'./临时垃圾-随时可删/2D_50k_png/pic_{count}.png')\n",
    "                count += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.6.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
